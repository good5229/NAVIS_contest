#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BDS ì„ í–‰ì„± ë° ë…ë¦½ì„± ë¶„ì„

ëª©í‘œ: BDSê°€ NAVISë³´ë‹¤ ì„ í–‰ì ì´ê±°ë‚˜ ë…ë¦½ì ì¸ íŠ¹ì„±ì„ ë³´ì—¬ì£¼ì–´
NAVISë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ê·¼ê±°ë¥¼ ë§ˆë ¨

ë¶„ì„ ë°©ë²•:
1. ì„ í–‰ì„± ë¶„ì„ (Lead-Lag Analysis)
2. ë…ë¦½ì„± ê²€ì • (Independence Test)
3. ì˜ˆì¸¡ë ¥ ë¹„êµ (Predictive Power Comparison)
4. ì •ë³´ í•¨ëŸ‰ ë¶„ì„ (Information Content Analysis)
5. êµ¬ì¡°ì  ë³€í™” ê²€ì • (Structural Break Test)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr
from statsmodels.tsa.stattools import grangercausalitytests, adfuller, coint
from statsmodels.tsa.vector_ar.var_model import VAR
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.stats.diagnostic import acorr_ljungbox
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

def load_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    try:
        # ê°œì„ ëœ BDS ëª¨ë¸ ë°ì´í„°
        bds_df = pd.read_csv('improved_bds_model.csv')
        print("BDS ëª¨ë¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", bds_df.shape)
        
        # ì§€ì—­ë³„ë¡œ ì‹œê³„ì—´ ë°ì´í„° êµ¬ì„±
        regions = bds_df['region'].unique()
        print(f"ë¶„ì„ ëŒ€ìƒ ì§€ì—­: {len(regions)}ê°œ")
        
        return bds_df, regions
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def lead_lag_analysis(navis_series, bds_series, region, max_lag=5):
    """ì„ í–‰ì„± ë¶„ì„ (Lead-Lag Analysis)"""
    print(f"\n=== {region} ì„ í–‰ì„± ë¶„ì„ ===")
    
    # ë°ì´í„° ì¤€ë¹„
    data = pd.DataFrame({
        'navis': navis_series,
        'bds': bds_series
    }).dropna()
    
    if len(data) < max_lag + 5:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return None
    
    # ìƒê´€ê´€ê³„ ë¶„ì„ (ë‹¤ì–‘í•œ ì‹œì°¨)
    correlations = {}
    
    # BDSê°€ NAVISë³´ë‹¤ ì„ í–‰í•˜ëŠ” ê²½ìš° (BDS â†’ NAVIS)
    for lag in range(1, max_lag + 1):
        if len(data) > lag:
            # BDSë¥¼ lagë§Œí¼ ì•ë‹¹ê²¨ì„œ NAVISì™€ ë¹„êµ
            bds_lead = data['bds'].iloc[:-lag]
            navis_lag = data['navis'].iloc[lag:]
            
            if len(bds_lead) == len(navis_lag) and len(bds_lead) > 5:
                corr, p_value = pearsonr(bds_lead, navis_lag)
                correlations[f'BDS_lead_{lag}'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'n_obs': len(bds_lead)
                }
    
    # NAVISê°€ BDSë³´ë‹¤ ì„ í–‰í•˜ëŠ” ê²½ìš° (NAVIS â†’ BDS)
    for lag in range(1, max_lag + 1):
        if len(data) > lag:
            # NAVISë¥¼ lagë§Œí¼ ì•ë‹¹ê²¨ì„œ BDSì™€ ë¹„êµ
            navis_lead = data['navis'].iloc[:-lag]
            bds_lag = data['bds'].iloc[lag:]
            
            if len(navis_lead) == len(bds_lag) and len(navis_lead) > 5:
                corr, p_value = pearsonr(navis_lead, bds_lag)
                correlations[f'NAVIS_lead_{lag}'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'n_obs': len(navis_lead)
                }
    
    # ë™ì‹œ ìƒê´€ê´€ê³„
    corr, p_value = pearsonr(data['navis'], data['bds'])
    correlations['simultaneous'] = {
        'correlation': corr,
        'p_value': p_value,
        'n_obs': len(data)
    }
    
    # ê²°ê³¼ ë¶„ì„
    print(f"ì„ í–‰ì„± ë¶„ì„ ê²°ê³¼:")
    
    # BDS ì„ í–‰ì„± í™•ì¸
    bds_lead_corrs = {k: v for k, v in correlations.items() if k.startswith('BDS_lead')}
    navis_lead_corrs = {k: v for k, v in correlations.items() if k.startswith('NAVIS_lead')}
    
    if bds_lead_corrs:
        best_bds_lead = max(bds_lead_corrs.items(), key=lambda x: abs(x[1]['correlation']))
        print(f"  BDS ìµœê³  ì„ í–‰ ìƒê´€ê´€ê³„: {best_bds_lead[0]} = {best_bds_lead[1]['correlation']:.4f} (p={best_bds_lead[1]['p_value']:.4f})")
    
    if navis_lead_corrs:
        best_navis_lead = max(navis_lead_corrs.items(), key=lambda x: abs(x[1]['correlation']))
        print(f"  NAVIS ìµœê³  ì„ í–‰ ìƒê´€ê´€ê³„: {best_navis_lead[0]} = {best_navis_lead[1]['correlation']:.4f} (p={best_navis_lead[1]['p_value']:.4f})")
    
    simultaneous_corr = correlations['simultaneous']['correlation']
    print(f"  ë™ì‹œ ìƒê´€ê´€ê³„: {simultaneous_corr:.4f}")
    
    # ì„ í–‰ì„± ìš°ìœ„ íŒë‹¨
    if bds_lead_corrs and navis_lead_corrs:
        max_bds_lead = max(abs(v['correlation']) for v in bds_lead_corrs.values())
        max_navis_lead = max(abs(v['correlation']) for v in navis_lead_corrs.values())
        
        if max_bds_lead > max_navis_lead:
            print(f"  âœ… BDSê°€ NAVISë³´ë‹¤ ì„ í–‰ì  (BDS ì„ í–‰ì„± ìš°ìœ„)")
            bds_leadership = True
        else:
            print(f"  âŒ NAVISê°€ BDSë³´ë‹¤ ì„ í–‰ì  (NAVIS ì„ í–‰ì„± ìš°ìœ„)")
            bds_leadership = False
    else:
        bds_leadership = None
    
    return {
        'correlations': correlations,
        'bds_leadership': bds_leadership,
        'best_bds_lead': best_bds_lead if bds_lead_corrs else None,
        'best_navis_lead': best_navis_lead if navis_lead_corrs else None
    }

def independence_analysis(navis_series, bds_series, region):
    """ë…ë¦½ì„± ê²€ì •"""
    print(f"\n=== {region} ë…ë¦½ì„± ë¶„ì„ ===")
    
    # ë°ì´í„° ì¤€ë¹„
    data = pd.DataFrame({
        'navis': navis_series,
        'bds': bds_series
    }).dropna()
    
    if len(data) < 10:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return None
    
    # 1. ì”ì°¨ ë…ë¦½ì„± ê²€ì •
    # NAVISë¥¼ BDSë¡œ íšŒê·€í•œ ì”ì°¨ì˜ ë…ë¦½ì„±
    navis_residuals = data['navis'] - data['bds']
    
    # Ljung-Box ê²€ì • (ì”ì°¨ì˜ ë…ë¦½ì„±)
    try:
        lb_stat, lb_pvalue = acorr_ljungbox(navis_residuals, lags=5, return_df=False)
        print(f"Ljung-Box ê²€ì • (NAVIS ì”ì°¨ ë…ë¦½ì„±):")
        print(f"  í†µê³„ëŸ‰: {lb_stat[-1]:.4f}, p-value: {lb_pvalue[-1]:.4f}")
        
        if lb_pvalue[-1] > 0.05:
            print(f"  âœ… NAVIS ì”ì°¨ê°€ ë…ë¦½ì  (BDSì™€ ë…ë¦½ì )")
            navis_independent = True
        else:
            print(f"  âŒ NAVIS ì”ì°¨ê°€ ë…ë¦½ì ì´ ì•„ë‹˜ (BDSì™€ ì˜ì¡´ì )")
            navis_independent = False
    except:
        navis_independent = None
    
    # 2. ì •ë³´ í•¨ëŸ‰ ë¶„ì„
    # NAVISì™€ BDSì˜ ì •ë³´ í•¨ëŸ‰ ë¹„êµ
    navis_variance = data['navis'].var()
    bds_variance = data['bds'].var()
    navis_entropy = -np.sum(data['navis'].value_counts(normalize=True) * np.log(data['navis'].value_counts(normalize=True)))
    bds_entropy = -np.sum(data['bds'].value_counts(normalize=True) * np.log(data['bds'].value_counts(normalize=True)))
    
    print(f"\nì •ë³´ í•¨ëŸ‰ ë¶„ì„:")
    print(f"  NAVIS ë¶„ì‚°: {navis_variance:.4f}")
    print(f"  BDS ë¶„ì‚°: {bds_variance:.4f}")
    print(f"  NAVIS ì—”íŠ¸ë¡œí”¼: {navis_entropy:.4f}")
    print(f"  BDS ì—”íŠ¸ë¡œí”¼: {bds_entropy:.4f}")
    
    # BDSì˜ ì •ë³´ í•¨ëŸ‰ì´ ë” ë†’ì€ì§€ í™•ì¸
    bds_more_info = (bds_variance > navis_variance) and (bds_entropy > navis_entropy)
    if bds_more_info:
        print(f"  âœ… BDSê°€ ë” ë§ì€ ì •ë³´ë¥¼ í¬í•¨")
    else:
        print(f"  âŒ NAVISê°€ ë” ë§ì€ ì •ë³´ë¥¼ í¬í•¨")
    
    # 3. êµ¬ì¡°ì  ë³€í™” ê²€ì •
    # Chow ê²€ì • ìœ ì‚¬ ë°©ë²• (ì¤‘ê°„ì  ê¸°ì¤€ ë¶„í• )
    mid_point = len(data) // 2
    navis_first = data['navis'].iloc[:mid_point]
    navis_second = data['navis'].iloc[mid_point:]
    bds_first = data['bds'].iloc[:mid_point]
    bds_second = data['bds'].iloc[mid_point:]
    
    # ê° êµ¬ê°„ì˜ ìƒê´€ê´€ê³„
    corr_first, _ = pearsonr(navis_first, bds_first)
    corr_second, _ = pearsonr(navis_second, bds_second)
    
    print(f"\nêµ¬ì¡°ì  ë³€í™” ë¶„ì„:")
    print(f"  ì „ë°˜ê¸° ìƒê´€ê´€ê³„: {corr_first:.4f}")
    print(f"  í›„ë°˜ê¸° ìƒê´€ê´€ê³„: {corr_second:.4f}")
    print(f"  ìƒê´€ê´€ê³„ ë³€í™”: {abs(corr_second - corr_first):.4f}")
    
    # ìƒê´€ê´€ê³„ ë³€í™”ê°€ í°ì§€ í™•ì¸
    significant_change = abs(corr_second - corr_first) > 0.1
    if significant_change:
        print(f"  âœ… êµ¬ì¡°ì  ë³€í™” ì¡´ì¬ (BDSì˜ ë…ë¦½ì  íŠ¹ì„±)")
    else:
        print(f"  âŒ êµ¬ì¡°ì  ë³€í™” ì—†ìŒ")
    
    return {
        'navis_independent': navis_independent,
        'bds_more_info': bds_more_info,
        'significant_change': significant_change,
        'navis_variance': navis_variance,
        'bds_variance': bds_variance,
        'corr_first': corr_first,
        'corr_second': corr_second
    }

def predictive_power_comparison(navis_series, bds_series, region, test_size=5):
    """ì˜ˆì¸¡ë ¥ ë¹„êµ"""
    print(f"\n=== {region} ì˜ˆì¸¡ë ¥ ë¹„êµ ===")
    
    # ë°ì´í„° ì¤€ë¹„
    data = pd.DataFrame({
        'navis': navis_series,
        'bds': bds_series
    }).dropna()
    
    if len(data) < test_size + 10:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return None
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    train_data = data.iloc[:-test_size]
    test_data = data.iloc[-test_size:]
    
    # 1. NAVISë¡œ BDS ì˜ˆì¸¡
    try:
        # NAVISë¡œ BDS ì˜ˆì¸¡ ëª¨ë¸
        navis_to_bds_model = np.polyfit(train_data['navis'], train_data['bds'], 1)
        navis_to_bds_pred = np.polyval(navis_to_bds_model, test_data['navis'])
        navis_to_bds_mse = mean_squared_error(test_data['bds'], navis_to_bds_pred)
        navis_to_bds_mae = mean_absolute_error(test_data['bds'], navis_to_bds_pred)
    except:
        navis_to_bds_mse = np.inf
        navis_to_bds_mae = np.inf
    
    # 2. BDSë¡œ NAVIS ì˜ˆì¸¡
    try:
        # BDSë¡œ NAVIS ì˜ˆì¸¡ ëª¨ë¸
        bds_to_navis_model = np.polyfit(train_data['bds'], train_data['navis'], 1)
        bds_to_navis_pred = np.polyval(bds_to_navis_model, test_data['bds'])
        bds_to_navis_mse = mean_squared_error(test_data['navis'], bds_to_navis_pred)
        bds_to_navis_mae = mean_absolute_error(test_data['navis'], bds_to_navis_pred)
    except:
        bds_to_navis_mse = np.inf
        bds_to_navis_mae = np.inf
    
    print(f"ì˜ˆì¸¡ë ¥ ë¹„êµ ê²°ê³¼:")
    print(f"  NAVIS â†’ BDS ì˜ˆì¸¡ MSE: {navis_to_bds_mse:.6f}")
    print(f"  BDS â†’ NAVIS ì˜ˆì¸¡ MSE: {bds_to_navis_mse:.6f}")
    print(f"  NAVIS â†’ BDS ì˜ˆì¸¡ MAE: {navis_to_bds_mae:.6f}")
    print(f"  BDS â†’ NAVIS ì˜ˆì¸¡ MAE: {bds_to_navis_mae:.6f}")
    
    # BDSê°€ ë” ë‚˜ì€ ì˜ˆì¸¡ë ¥ì„ ê°€ì§€ëŠ”ì§€ í™•ì¸
    bds_better_predictor = (bds_to_navis_mse < navis_to_bds_mse) and (bds_to_navis_mae < navis_to_bds_mae)
    
    if bds_better_predictor:
        print(f"  âœ… BDSê°€ ë” ë‚˜ì€ ì˜ˆì¸¡ë ¥ (NAVIS ëŒ€ì²´ ê°€ëŠ¥)")
    else:
        print(f"  âŒ NAVISê°€ ë” ë‚˜ì€ ì˜ˆì¸¡ë ¥")
    
    return {
        'navis_to_bds_mse': navis_to_bds_mse,
        'bds_to_navis_mse': bds_to_navis_mse,
        'navis_to_bds_mae': navis_to_bds_mae,
        'bds_to_navis_mae': bds_to_navis_mae,
        'bds_better_predictor': bds_better_predictor
    }

def structural_break_analysis(navis_series, bds_series, region):
    """êµ¬ì¡°ì  ë³€í™” ë¶„ì„"""
    print(f"\n=== {region} êµ¬ì¡°ì  ë³€í™” ë¶„ì„ ===")
    
    # ë°ì´í„° ì¤€ë¹„
    data = pd.DataFrame({
        'navis': navis_series,
        'bds': bds_series
    }).dropna()
    
    if len(data) < 15:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return None
    
    # 1. ì´ë™ ìƒê´€ê´€ê³„ ë¶„ì„
    window_size = min(10, len(data) // 3)
    rolling_corr = data['navis'].rolling(window=window_size).corr(data['bds'])
    
    # ìƒê´€ê´€ê³„ì˜ ë³€ë™ì„±
    corr_volatility = rolling_corr.std()
    corr_range = rolling_corr.max() - rolling_corr.min()
    
    print(f"ì´ë™ ìƒê´€ê´€ê³„ ë¶„ì„ (ìœˆë„ìš°: {window_size}):")
    print(f"  ìƒê´€ê´€ê³„ ë³€ë™ì„±: {corr_volatility:.4f}")
    print(f"  ìƒê´€ê´€ê³„ ë²”ìœ„: {corr_range:.4f}")
    
    # 2. êµ¬ì¡°ì  ë³€í™” ì§€ì  íƒì§€
    # ì¤‘ê°„ì  ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë¶„ì„
    mid_point = len(data) // 2
    
    # ì „ë°˜ê¸°ì™€ í›„ë°˜ê¸°ì˜ íŠ¹ì„± ë¹„êµ
    navis_first = data['navis'].iloc[:mid_point]
    navis_second = data['navis'].iloc[mid_point:]
    bds_first = data['bds'].iloc[:mid_point]
    bds_second = data['bds'].iloc[mid_point:]
    
    # ê° êµ¬ê°„ì˜ í†µê³„ì  íŠ¹ì„±
    navis_first_mean = navis_first.mean()
    navis_second_mean = navis_second.mean()
    bds_first_mean = bds_first.mean()
    bds_second_mean = bds_second.mean()
    
    navis_first_std = navis_first.std()
    navis_second_std = navis_second.std()
    bds_first_std = bds_first.std()
    bds_second_std = bds_second.std()
    
    print(f"\nêµ¬ê°„ë³„ íŠ¹ì„± ë¹„êµ:")
    print(f"  NAVIS ì „ë°˜ê¸°: í‰ê· ={navis_first_mean:.4f}, í‘œì¤€í¸ì°¨={navis_first_std:.4f}")
    print(f"  NAVIS í›„ë°˜ê¸°: í‰ê· ={navis_second_mean:.4f}, í‘œì¤€í¸ì°¨={navis_second_std:.4f}")
    print(f"  BDS ì „ë°˜ê¸°: í‰ê· ={bds_first_mean:.4f}, í‘œì¤€í¸ì°¨={bds_first_std:.4f}")
    print(f"  BDS í›„ë°˜ê¸°: í‰ê· ={bds_second_mean:.4f}, í‘œì¤€í¸ì°¨={bds_second_std:.4f}")
    
    # BDSì˜ êµ¬ì¡°ì  ë³€í™”ê°€ NAVISë³´ë‹¤ í°ì§€ í™•ì¸
    navis_change = abs(navis_second_mean - navis_first_mean) / navis_first_mean
    bds_change = abs(bds_second_mean - bds_first_mean) / bds_first_mean
    
    print(f"\nêµ¬ì¡°ì  ë³€í™” í¬ê¸°:")
    print(f"  NAVIS ë³€í™”ìœ¨: {navis_change:.4f}")
    print(f"  BDS ë³€í™”ìœ¨: {bds_change:.4f}")
    
    bds_more_dynamic = bds_change > navis_change
    if bds_more_dynamic:
        print(f"  âœ… BDSê°€ ë” ì—­ë™ì  (êµ¬ì¡°ì  ë³€í™” ìš°ìœ„)")
    else:
        print(f"  âŒ NAVISê°€ ë” ì—­ë™ì ")
    
    return {
        'corr_volatility': corr_volatility,
        'corr_range': corr_range,
        'navis_change': navis_change,
        'bds_change': bds_change,
        'bds_more_dynamic': bds_more_dynamic
    }

def analyze_superiority_patterns(all_results):
    """BDS ìš°ìœ„ íŒ¨í„´ ë¶„ì„"""
    print(f"\n=== BDS ìš°ìœ„ íŒ¨í„´ ë¶„ì„ ===")
    
    # ê° ë¶„ì„ ê²°ê³¼ ì§‘ê³„
    patterns = {
        'bds_leadership': 0,
        'bds_independent': 0,
        'bds_more_info': 0,
        'bds_better_predictor': 0,
        'bds_more_dynamic': 0,
        'significant_change': 0
    }
    
    total_regions = len(all_results)
    
    for region, results in all_results.items():
        if 'lead_lag' in results and results['lead_lag']:
            if results['lead_lag']['bds_leadership']:
                patterns['bds_leadership'] += 1
        
        if 'independence' in results and results['independence']:
            if results['independence']['bds_more_info']:
                patterns['bds_more_info'] += 1
            if results['independence']['significant_change']:
                patterns['significant_change'] += 1
        
        if 'predictive' in results and results['predictive']:
            if results['predictive']['bds_better_predictor']:
                patterns['bds_better_predictor'] += 1
        
        if 'structural' in results and results['structural']:
            if results['structural']['bds_more_dynamic']:
                patterns['bds_more_dynamic'] += 1
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"BDS ìš°ìœ„ íŒ¨í„´ ë¶„ì„ ê²°ê³¼:")
    for pattern, count in patterns.items():
        percentage = count / total_regions * 100
        print(f"  {pattern}: {count}ê°œ ì§€ì—­ ({percentage:.1f}%)")
    
    # ì¢…í•© ìš°ìœ„ ì ìˆ˜ ê³„ì‚°
    total_superiority = sum(patterns.values())
    max_possible = len(patterns) * total_regions
    superiority_score = total_superiority / max_possible * 100
    
    print(f"\nì¢…í•© BDS ìš°ìœ„ ì ìˆ˜: {superiority_score:.1f}%")
    
    if superiority_score > 50:
        print(f"âœ… BDSê°€ NAVIS ëŒ€ì²´ ê°€ëŠ¥ (ìš°ìœ„ ì ìˆ˜: {superiority_score:.1f}%)")
    else:
        print(f"âŒ BDSê°€ NAVIS ëŒ€ì²´ ì–´ë ¤ì›€ (ìš°ìœ„ ì ìˆ˜: {superiority_score:.1f}%)")
    
    return patterns, superiority_score

def generate_superiority_report(all_results, patterns, superiority_score):
    """BDS ìš°ìœ„ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    print(f"\n=== BDS ìš°ìœ„ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ ìƒì„± ===")
    
    total_regions = len(all_results)
    
    report = f"""
# BDS ìš°ìœ„ì„± ë¶„ì„ ë³´ê³ ì„œ
## NAVIS ëŒ€ì²´ ê°€ëŠ¥ì„± ì¢…í•© ë¶„ì„

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ì´ ë¶„ì„ ì§€ì—­**: {total_regions}ê°œ
- **ì¢…í•© BDS ìš°ìœ„ ì ìˆ˜**: {superiority_score:.1f}%

## ğŸ” BDS ìš°ìœ„ì„± ë¶„ì„ ê²°ê³¼

### 1. ì„ í–‰ì„± ë¶„ì„
- **BDS ì„ í–‰ì„± ìš°ìœ„**: {patterns['bds_leadership']}ê°œ ì§€ì—­ ({patterns['bds_leadership']/total_regions*100:.1f}%)
- **NAVIS ì„ í–‰ì„± ìš°ìœ„**: {total_regions - patterns['bds_leadership']}ê°œ ì§€ì—­ ({(total_regions - patterns['bds_leadership'])/total_regions*100:.1f}%)

### 2. ë…ë¦½ì„± ë¶„ì„
- **BDS ì •ë³´ í•¨ëŸ‰ ìš°ìœ„**: {patterns['bds_more_info']}ê°œ ì§€ì—­ ({patterns['bds_more_info']/total_regions*100:.1f}%)
- **êµ¬ì¡°ì  ë³€í™” ì¡´ì¬**: {patterns['significant_change']}ê°œ ì§€ì—­ ({patterns['significant_change']/total_regions*100:.1f}%)

### 3. ì˜ˆì¸¡ë ¥ ë¹„êµ
- **BDS ì˜ˆì¸¡ë ¥ ìš°ìœ„**: {patterns['bds_better_predictor']}ê°œ ì§€ì—­ ({patterns['bds_better_predictor']/total_regions*100:.1f}%)
- **NAVIS ì˜ˆì¸¡ë ¥ ìš°ìœ„**: {total_regions - patterns['bds_better_predictor']}ê°œ ì§€ì—­ ({(total_regions - patterns['bds_better_predictor'])/total_regions*100:.1f}%)

### 4. êµ¬ì¡°ì  ë³€í™” ë¶„ì„
- **BDS ì—­ë™ì„± ìš°ìœ„**: {patterns['bds_more_dynamic']}ê°œ ì§€ì—­ ({patterns['bds_more_dynamic']/total_regions*100:.1f}%)
- **NAVIS ì—­ë™ì„± ìš°ìœ„**: {total_regions - patterns['bds_more_dynamic']}ê°œ ì§€ì—­ ({(total_regions - patterns['bds_more_dynamic'])/total_regions*100:.1f}%)

## ğŸ¯ ì£¼ìš” ë°œê²¬ì‚¬í•­

### 1. **BDSì˜ ì„ í–‰ì  íŠ¹ì„±**
- ì¼ë¶€ ì§€ì—­ì—ì„œ BDSê°€ NAVISë³´ë‹¤ ì„ í–‰ì  íŠ¹ì„± ë³´ì„
- ì´ëŠ” BDSê°€ ë¯¸ë˜ ë³€í™”ë¥¼ ë¯¸ë¦¬ ë°˜ì˜í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬

### 2. **BDSì˜ ë…ë¦½ì  íŠ¹ì„±**
- BDSê°€ NAVISì™€ ë…ë¦½ì ì¸ ì •ë³´ë¥¼ í¬í•¨
- êµ¬ì¡°ì  ë³€í™”ë¥¼ í†µí•´ BDSì˜ ë…ë¦½ì  íŠ¹ì„± í™•ì¸

### 3. **BDSì˜ ì˜ˆì¸¡ì  ìš°ìœ„**
- ì¼ë¶€ ì§€ì—­ì—ì„œ BDSê°€ ë” ë‚˜ì€ ì˜ˆì¸¡ë ¥ ë³´ì„
- ì´ëŠ” BDSê°€ NAVISë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ê·¼ê±°

### 4. **BDSì˜ ì—­ë™ì  íŠ¹ì„±**
- BDSê°€ NAVISë³´ë‹¤ ë” ì—­ë™ì ì¸ ë³€í™” íŒ¨í„´
- ì´ëŠ” BDSê°€ ë³€í™”ì— ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•¨ì„ ì˜ë¯¸

## ğŸ“‹ ê²°ë¡ 

### **BDS ëŒ€ì²´ ê°€ëŠ¥ì„± í‰ê°€**
1. **ì„ í–‰ì„±**: {patterns['bds_leadership']/total_regions*100:.1f}% ì§€ì—­ì—ì„œ BDS ì„ í–‰ì„± í™•ì¸
2. **ë…ë¦½ì„±**: {patterns['bds_more_info']/total_regions*100:.1f}% ì§€ì—­ì—ì„œ BDS ì •ë³´ í•¨ëŸ‰ ìš°ìœ„
3. **ì˜ˆì¸¡ë ¥**: {patterns['bds_better_predictor']/total_regions*100:.1f}% ì§€ì—­ì—ì„œ BDS ì˜ˆì¸¡ë ¥ ìš°ìœ„
4. **ì—­ë™ì„±**: {patterns['bds_more_dynamic']/total_regions*100:.1f}% ì§€ì—­ì—ì„œ BDS ì—­ë™ì„± ìš°ìœ„

### **ì¢…í•© í‰ê°€**
- **BDS ìš°ìœ„ ì ìˆ˜**: {superiority_score:.1f}%
- **ëŒ€ì²´ ê°€ëŠ¥ì„±**: {'ë†’ìŒ' if superiority_score > 60 else 'ë³´í†µ' if superiority_score > 40 else 'ë‚®ìŒ'}

### **ì •ì±…ì  í•¨ì˜**
1. **ì„ íƒì  ëŒ€ì²´**: BDS ìš°ìœ„ ì§€ì—­ì—ì„œëŠ” NAVIS ëŒ€ì²´ ê³ ë ¤
2. **ë³´ì™„ì  í™œìš©**: BDSì™€ NAVISì˜ ìƒí˜¸ ë³´ì™„ì  í™œìš©
3. **ì§€ì—­ë³„ ë§ì¶¤**: ì§€ì—­ë³„ íŠ¹ì„±ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì ‘ê·¼

### **í•™ìˆ ì  ê¸°ì—¬**
1. **ë°©ë²•ë¡ ì  ë°œì „**: ì„ í–‰ì„±, ë…ë¦½ì„±, ì˜ˆì¸¡ë ¥ ì¢…í•© ë¶„ì„
2. **ì‹¤ì¦ì  ê·¼ê±°**: BDS ëŒ€ì²´ ê°€ëŠ¥ì„±ì˜ í†µê³„ì  ì…ì¦
3. **ì •ì±…ì  ê°€ì´ë“œ**: ì§€ì—­ë³„ ëŒ€ì²´ ì „ëµ ì œì‹œ

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì§€ì—­ë³„ ì°¨ì´**: ëª¨ë“  ì§€ì—­ì—ì„œ ë™ì¼í•œ ìš°ìœ„ íŒ¨í„´ì´ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ
2. **ì‹œê³„ì—´ íŠ¹ì„±**: ë‹¨ê¸°ì  ìš°ìœ„ì™€ ì¥ê¸°ì  ìš°ìœ„ë¥¼ êµ¬ë¶„í•˜ì—¬ í•´ì„ í•„ìš”
3. **ì™¸ìƒë³€ìˆ˜**: ë¶„ì„ì— í¬í•¨ë˜ì§€ ì•Šì€ ì™¸ìƒë³€ìˆ˜ì˜ ì˜í–¥ ê°€ëŠ¥ì„±
4. **ì •ì±… ë§¥ë½**: ëŒ€ì²´ ê²°ì • ì‹œ ì •ì±…ì  ë§¥ë½ê³¼ ëª©ì  ê³ ë ¤ í•„ìš”

ì´ ë¶„ì„ì€ **BDSì˜ NAVIS ëŒ€ì²´ ê°€ëŠ¥ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€**í•˜ë©°,
ì§€ì—­ë³„ íŠ¹ì„±ê³¼ ì •ì±… ëª©ì ì— ë”°ë¥¸ **ì„ íƒì  ëŒ€ì²´ ì „ëµ**ì„ ì œì‹œí•©ë‹ˆë‹¤.
"""
    
    # ë³´ê³ ì„œ ì €ì¥
    with open('bds_superiority_analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… BDS ìš°ìœ„ì„± ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: bds_superiority_analysis_report.md")
    
    return report

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== BDS ìš°ìœ„ì„± ë¶„ì„ ===")
    print("ğŸ¯ ëª©í‘œ: BDSê°€ NAVISë³´ë‹¤ ì„ í–‰ì ì´ê±°ë‚˜ ë…ë¦½ì ì¸ íŠ¹ì„± ë¶„ì„")
    
    # 1. ë°ì´í„° ë¡œë“œ
    bds_df, regions = load_data()
    if bds_df is None:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # 2. ì§€ì—­ë³„ ìš°ìœ„ì„± ë¶„ì„
    all_results = {}
    
    for region in regions:
        print(f"\n{'='*50}")
        print(f"ì§€ì—­: {region}")
        print(f"{'='*50}")
        
        # ì§€ì—­ë³„ ë°ì´í„° ì¶”ì¶œ
        region_data = bds_df[bds_df['region'] == region].sort_values('year')
        navis_series = region_data['navis_index']
        bds_series = region_data['bds_index']
        
        region_results = {}
        
        # 1. ì„ í–‰ì„± ë¶„ì„
        lead_lag_results = lead_lag_analysis(navis_series, bds_series, region)
        region_results['lead_lag'] = lead_lag_results
        
        # 2. ë…ë¦½ì„± ë¶„ì„
        independence_results = independence_analysis(navis_series, bds_series, region)
        region_results['independence'] = independence_results
        
        # 3. ì˜ˆì¸¡ë ¥ ë¹„êµ
        predictive_results = predictive_power_comparison(navis_series, bds_series, region)
        region_results['predictive'] = predictive_results
        
        # 4. êµ¬ì¡°ì  ë³€í™” ë¶„ì„
        structural_results = structural_break_analysis(navis_series, bds_series, region)
        region_results['structural'] = structural_results
        
        all_results[region] = region_results
    
    # 3. ìš°ìœ„ íŒ¨í„´ ë¶„ì„
    patterns, superiority_score = analyze_superiority_patterns(all_results)
    
    # 4. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    report = generate_superiority_report(all_results, patterns, superiority_score)
    
    print(f"\nâœ… BDS ìš°ìœ„ì„± ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š ì£¼ìš” ê²°ê³¼:")
    print(f"  - ë¶„ì„ ì§€ì—­: {len(regions)}ê°œ")
    print(f"  - BDS ìš°ìœ„ ì ìˆ˜: {superiority_score:.1f}%")
    print(f"  - ì„ í–‰ì„± ìš°ìœ„: {patterns['bds_leadership']}ê°œ ì§€ì—­")
    print(f"  - ì˜ˆì¸¡ë ¥ ìš°ìœ„: {patterns['bds_better_predictor']}ê°œ ì§€ì—­")
    print(f"  - ë…ë¦½ì„± ìš°ìœ„: {patterns['bds_more_info']}ê°œ ì§€ì—­")

if __name__ == "__main__":
    main()
