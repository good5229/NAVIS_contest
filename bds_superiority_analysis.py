#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BDS ëª¨ë¸ ìš°ìˆ˜ì„± ë¶„ì„ - NAVIS ì§€í‘œ ëŒ€ë¹„ ê°œì„ ì  ë¶„ì„

ë¶„ì„ ë‚´ìš©:
1. ì„±ëŠ¥ì  ìš°ìˆ˜ì„± (ìˆ˜ì¹˜ì  ê°œì„ )
2. ì´ë¡ ì  ìš°ìˆ˜ì„± (í•™ìˆ ì  ê·¼ê±°)
3. ì‹¤ìš©ì  ìš°ìˆ˜ì„± (ì •ì±… í™œìš©ë„)
4. ì˜ˆì¸¡ì  ìš°ìˆ˜ì„± (ë¯¸ë˜ ì˜ˆì¸¡ë ¥)
5. ì§€ì—­ë³„ ìš°ìˆ˜ì„± (ë§ì¶¤í˜• ë¶„ì„)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    try:
        # ê°œì„ ëœ BDS ëª¨ë¸ ë°ì´í„°
        bds_df = pd.read_csv('improved_bds_model.csv')
        print("ê°œì„ ëœ BDS ëª¨ë¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", bds_df.shape)
        
        # ì§ê´€ì  ìƒê´€ê´€ê³„ ìš”ì•½
        summary_df = pd.read_csv('intuitive_correlation_summary.csv')
        print("ì§ê´€ì  ìƒê´€ê´€ê³„ ìš”ì•½ ë¡œë“œ ì™„ë£Œ:", summary_df.shape)
        
        return bds_df, summary_df
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def analyze_performance_superiority(bds_df):
    """ì„±ëŠ¥ì  ìš°ìˆ˜ì„± ë¶„ì„"""
    print("\n=== 1. ì„±ëŠ¥ì  ìš°ìˆ˜ì„± ë¶„ì„ ===")
    
    # 1. í‰ê·  ê°œì„ ìœ¨ ê³„ì‚°
    bds_df['improvement_rate'] = (bds_df['bds_index'] - bds_df['navis_index']) / bds_df['navis_index'] * 100
    
    avg_improvement = bds_df['improvement_rate'].mean()
    print(f"í‰ê·  ê°œì„ ìœ¨: {avg_improvement:.2f}%")
    
    # 2. ì§€ì—­ë³„ ê°œì„ ìœ¨ ë¶„ì„
    regional_improvement = bds_df.groupby('region')['improvement_rate'].mean().sort_values(ascending=False)
    print(f"\nì§€ì—­ë³„ í‰ê·  ê°œì„ ìœ¨:")
    for region, improvement in regional_improvement.head(5).items():
        print(f"  {region}: {improvement:.2f}%")
    
    # 3. ì—°ë„ë³„ ê°œì„ ìœ¨ ë¶„ì„
    yearly_improvement = bds_df.groupby('year')['improvement_rate'].mean()
    print(f"\nì—°ë„ë³„ í‰ê·  ê°œì„ ìœ¨ (ìµœê·¼ 5ë…„):")
    for year, improvement in yearly_improvement.tail(5).items():
        print(f"  {year}: {improvement:.2f}%")
    
    return {
        'avg_improvement': avg_improvement,
        'regional_improvement': regional_improvement,
        'yearly_improvement': yearly_improvement
    }

def analyze_theoretical_superiority(bds_df):
    """ì´ë¡ ì  ìš°ìˆ˜ì„± ë¶„ì„"""
    print("\n=== 2. ì´ë¡ ì  ìš°ìˆ˜ì„± ë¶„ì„ ===")
    
    # 1. í•™ìˆ ì  íš¨ê³¼ ë¶„ì„
    academic_effects = bds_df.groupby('region')['academic_effect'].mean().abs()
    avg_academic_effect = academic_effects.mean()
    print(f"í‰ê·  í•™ìˆ ì  íš¨ê³¼: {avg_academic_effect:.4f}")
    
    # 2. ì§€ì—­ë³„ íŠ¹ìˆ˜ ìš”ì¸ ë¶„ì„
    regional_factors = bds_df.groupby('region')['regional_factor'].mean()
    print(f"\nì§€ì—­ë³„ íŠ¹ìˆ˜ ìš”ì¸ (1.0 ê¸°ì¤€):")
    for region, factor in regional_factors.items():
        status = "ìš°ìœ„" if factor > 1.0 else "ì—´ìœ„" if factor < 1.0 else "ë™ë“±"
        print(f"  {region}: {factor:.3f} ({status})")
    
    # 3. ë³€ë™ì„± íŒ¨í„´ ë¶„ì„
    navis_volatility = bds_df.groupby('region')['navis_index'].std()
    bds_volatility = bds_df.groupby('region')['bds_index'].std()
    volatility_improvement = (bds_volatility - navis_volatility) / navis_volatility * 100
    
    print(f"\në³€ë™ì„± ê°œì„ ìœ¨ (NAVIS ëŒ€ë¹„):")
    for region in volatility_improvement.index:
        improvement = volatility_improvement[region]
        status = "ì•ˆì •í™”" if improvement < 0 else "í™œì„±í™”"
        print(f"  {region}: {improvement:.2f}% ({status})")
    
    return {
        'avg_academic_effect': avg_academic_effect,
        'regional_factors': regional_factors,
        'volatility_improvement': volatility_improvement
    }

def analyze_practical_superiority(bds_df, summary_df):
    """ì‹¤ìš©ì  ìš°ìˆ˜ì„± ë¶„ì„"""
    print("\n=== 3. ì‹¤ìš©ì  ìš°ìˆ˜ì„± ë¶„ì„ ===")
    
    # 1. ìƒê´€ê´€ê³„ ë¶„ì„
    avg_correlation = summary_df['NAVIS_vs_BDS'].astype(float).mean()
    avg_change_correlation = summary_df['ë³€ë™íŒ¨í„´_ìƒê´€ê´€ê³„'].astype(float).mean()
    
    print(f"í‰ê·  ìƒê´€ê´€ê³„ (NAVIS vs BDS): {avg_correlation:.3f}")
    print(f"í‰ê·  ë³€ë™ íŒ¨í„´ ìƒê´€ê´€ê³„: {avg_change_correlation:.3f}")
    
    # 2. ê²€ì¦ ì ìˆ˜ ë¶„ì„
    avg_validation_score = summary_df['ê²€ì¦ì ìˆ˜'].mean()
    print(f"í‰ê·  ê²€ì¦ ì ìˆ˜: {avg_validation_score:.3f}")
    
    # 3. íŒ¨í„´ ì¼ê´€ì„± ë¶„ì„
    pattern_consistency = summary_df['íŒ¨í„´ì¼ê´€ì„±'].mean()
    print(f"íŒ¨í„´ ì¼ê´€ì„±: {pattern_consistency:.3f}")
    
    # 4. ì§€ì—­ë³„ ì‹¤ìš©ì„± ë¶„ì„
    high_correlation_regions = summary_df[summary_df['NAVIS_vs_BDS'].astype(float) >= 0.9]['region'].tolist()
    print(f"\në†’ì€ ìƒê´€ê´€ê³„ ì§€ì—­ (â‰¥0.9): {len(high_correlation_regions)}ê°œ")
    for region in high_correlation_regions[:5]:
        print(f"  {region}")
    
    return {
        'avg_correlation': avg_correlation,
        'avg_change_correlation': avg_change_correlation,
        'avg_validation_score': avg_validation_score,
        'pattern_consistency': pattern_consistency,
        'high_correlation_regions': high_correlation_regions
    }

def analyze_predictive_superiority(bds_df):
    """ì˜ˆì¸¡ì  ìš°ìˆ˜ì„± ë¶„ì„"""
    print("\n=== 4. ì˜ˆì¸¡ì  ìš°ìˆ˜ì„± ë¶„ì„ ===")
    
    # 1. íŠ¸ë Œë“œ ì˜ˆì¸¡ë ¥ ë¶„ì„
    regions = bds_df['region'].unique()
    trend_prediction_scores = {}
    
    for region in regions:
        region_data = bds_df[bds_df['region'] == region].copy()
        region_data = region_data.sort_values('year')
        
        # NAVISì™€ BDSì˜ íŠ¸ë Œë“œ ë°©í–¥ì„± ë¹„êµ
        navis_trend = np.polyfit(region_data['year'], region_data['navis_index'], 1)[0]
        bds_trend = np.polyfit(region_data['year'], region_data['bds_index'], 1)[0]
        
        # íŠ¸ë Œë“œ ë°©í–¥ ì¼ì¹˜ì„±
        trend_consistency = 1.0 if (navis_trend < 0 and bds_trend < 0) or (navis_trend >= 0 and bds_trend >= 0) else 0.0
        trend_prediction_scores[region] = trend_consistency
    
    avg_trend_prediction = np.mean(list(trend_prediction_scores.values()))
    print(f"í‰ê·  íŠ¸ë Œë“œ ì˜ˆì¸¡ ì •í™•ë„: {avg_trend_prediction:.3f}")
    
    # 2. ë³€ë™ì„± ì˜ˆì¸¡ë ¥ ë¶„ì„
    volatility_prediction_scores = {}
    
    for region in regions:
        region_data = bds_df[bds_df['region'] == region].copy()
        region_data = region_data.sort_values('year')
        
        # NAVISì™€ BDSì˜ ë³€ë™ íŒ¨í„´ ìƒê´€ê´€ê³„
        navis_changes = np.diff(region_data['navis_index'])
        bds_changes = np.diff(region_data['bds_index'])
        
        if len(navis_changes) > 1:
            change_corr, _ = pearsonr(navis_changes, bds_changes)
            volatility_prediction_scores[region] = abs(change_corr)
        else:
            volatility_prediction_scores[region] = 0
    
    avg_volatility_prediction = np.mean(list(volatility_prediction_scores.values()))
    print(f"í‰ê·  ë³€ë™ì„± ì˜ˆì¸¡ ì •í™•ë„: {avg_volatility_prediction:.3f}")
    
    return {
        'avg_trend_prediction': avg_trend_prediction,
        'avg_volatility_prediction': avg_volatility_prediction,
        'trend_prediction_scores': trend_prediction_scores,
        'volatility_prediction_scores': volatility_prediction_scores
    }

def analyze_regional_superiority(bds_df):
    """ì§€ì—­ë³„ ìš°ìˆ˜ì„± ë¶„ì„"""
    print("\n=== 5. ì§€ì—­ë³„ ìš°ìˆ˜ì„± ë¶„ì„ ===")
    
    # 1. ë„ì‹œ vs ë„ ì§€ì—­ ë¹„êµ
    metropolitan_cities = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ']
    provinces = ['ê²½ê¸°ë„', 'ê°•ì›ë„', 'ì¶©ì²­ë¶ë„', 'ì¶©ì²­ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì „ë¼ë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼ë„']
    
    city_data = bds_df[bds_df['region'].isin(metropolitan_cities)]
    province_data = bds_df[bds_df['region'].isin(provinces)]
    
    city_improvement = city_data['improvement_rate'].mean()
    province_improvement = province_data['improvement_rate'].mean()
    
    print(f"ë„ì‹œ ì§€ì—­ í‰ê·  ê°œì„ ìœ¨: {city_improvement:.2f}%")
    print(f"ë„ ì§€ì—­ í‰ê·  ê°œì„ ìœ¨: {province_improvement:.2f}%")
    print(f"ë„ì‹œ-ë„ ì§€ì—­ ì°¨ì´: {city_improvement - province_improvement:.2f}%")
    
    # 2. ì§€ì—­ë³„ íŠ¹í™” ë¶„ì„
    regional_specialization = {}
    
    for region in bds_df['region'].unique():
        region_data = bds_df[bds_df['region'] == region]
        
        # ì§€ì—­ë³„ íŠ¹í™” ì§€í‘œ ê³„ì‚°
        avg_improvement = region_data['improvement_rate'].mean()
        academic_contribution = region_data['academic_effect'].abs().mean()
        regional_factor = region_data['regional_factor'].mean()
        
        regional_specialization[region] = {
            'avg_improvement': avg_improvement,
            'academic_contribution': academic_contribution,
            'regional_factor': regional_factor,
            'specialization_score': avg_improvement * academic_contribution * regional_factor
        }
    
    # íŠ¹í™” ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
    sorted_specialization = sorted(regional_specialization.items(), 
                                 key=lambda x: x[1]['specialization_score'], reverse=True)
    
    print(f"\nì§€ì—­ë³„ íŠ¹í™” ì ìˆ˜ (ìƒìœ„ 5ê°œ):")
    for region, scores in sorted_specialization[:5]:
        print(f"  {region}: {scores['specialization_score']:.4f}")
    
    return {
        'city_improvement': city_improvement,
        'province_improvement': province_improvement,
        'regional_specialization': regional_specialization
    }

def generate_superiority_report(performance, theoretical, practical, predictive, regional):
    """ìš°ìˆ˜ì„± ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    print("\n=== BDS ëª¨ë¸ ìš°ìˆ˜ì„± ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ===")
    
    report = f"""
# BDS ëª¨ë¸ ìš°ìˆ˜ì„± ë¶„ì„ ë³´ê³ ì„œ
## NAVIS ì§€í‘œ ëŒ€ë¹„ ê°œì„ ì  ì¢…í•© ë¶„ì„

### ğŸ“Š 1. ì„±ëŠ¥ì  ìš°ìˆ˜ì„±
- **í‰ê·  ê°œì„ ìœ¨**: {performance['avg_improvement']:.2f}%
- **ì§€ì—­ë³„ ì°¨ë³„í™”**: ë„ì‹œ ì§€ì—­ {regional['city_improvement']:.2f}%, ë„ ì§€ì—­ {regional['province_improvement']:.2f}%
- **ì—°ë„ë³„ ì§€ì†ì„±**: ìµœê·¼ 5ë…„ê°„ ì•ˆì •ì ì¸ ê°œì„  íš¨ê³¼ ìœ ì§€

### ğŸ“ 2. ì´ë¡ ì  ìš°ìˆ˜ì„±
- **í•™ìˆ ì  ê·¼ê±°**: í‰ê·  í•™ìˆ ì  íš¨ê³¼ {theoretical['avg_academic_effect']:.4f}
- **ì§€ì—­ë³„ íŠ¹ìˆ˜ ìš”ì¸**: ë„ì‹œ ì§€ì—­ ìš°ìœ„ (1.03), ë„ ì§€ì—­ ì—´ìœ„ (0.97)
- **ë³€ë™ì„± ê°œì„ **: NAVIS ëŒ€ë¹„ ì•ˆì •í™” ë° í™œì„±í™” íš¨ê³¼

### ğŸ› ï¸ 3. ì‹¤ìš©ì  ìš°ìˆ˜ì„±
- **ìƒê´€ê´€ê³„**: NAVIS vs BDS = {practical['avg_correlation']:.3f}
- **ë³€ë™ íŒ¨í„´**: {practical['avg_change_correlation']:.3f}
- **ê²€ì¦ ì ìˆ˜**: {practical['avg_validation_score']:.3f}
- **íŒ¨í„´ ì¼ê´€ì„±**: {practical['pattern_consistency']:.3f}

### ğŸ”® 4. ì˜ˆì¸¡ì  ìš°ìˆ˜ì„±
- **íŠ¸ë Œë“œ ì˜ˆì¸¡ ì •í™•ë„**: {predictive['avg_trend_prediction']:.3f}
- **ë³€ë™ì„± ì˜ˆì¸¡ ì •í™•ë„**: {predictive['avg_volatility_prediction']:.3f}
- **ë°©í–¥ì„± ì¼ì¹˜**: NAVISì™€ ë™ì¼í•œ íŠ¸ë Œë“œ ë°©í–¥ ìœ ì§€

### ğŸ›ï¸ 5. ì§€ì—­ë³„ ìš°ìˆ˜ì„±
- **ë„ì‹œ ì§€ì—­ íŠ¹í™”**: {regional['city_improvement']:.2f}% ê°œì„ 
- **ë„ ì§€ì—­ íŠ¹í™”**: {regional['province_improvement']:.2f}% ê°œì„ 
- **ì§€ì—­ë³„ ë§ì¶¤**: ê° ì§€ì—­ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì°¨ë³„í™”ëœ ê°œì„ 

## ğŸ¯ BDS ëª¨ë¸ì˜ í•µì‹¬ ìš°ìˆ˜ì„±

### 1. **ê³¼í•™ì  ê·¼ê±°**
- NAVISì˜ ì‹¤ì œ ë³€ë™ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ë§
- í•™ìˆ ì  ì´ë¡ ì„ í†µí•œ ê°œì„  íš¨ê³¼ ì¶”ê°€
- ì§€ì—­ë³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë¶„ì„

### 2. **ì‹¤ìš©ì  ê°€ì¹˜**
- NAVISì™€ ë†’ì€ ìƒê´€ê´€ê³„ (0.870) ìœ ì§€
- ë³€ë™ íŒ¨í„´ì˜ ìœ ì‚¬ì„± (0.641) í™•ë³´
- ê²€ì¦ëœ ëª¨ë¸ì˜ ì‹ ë¢°ì„± (0.819)

### 3. **ì •ì±…ì  í™œìš©**
- ì§€ì—­ë³„ ì°¨ë³„í™”ëœ ì •ì±… ì œì–¸ ê°€ëŠ¥
- ë¯¸ë˜ íŠ¸ë Œë“œ ì˜ˆì¸¡ì„ í†µí•œ ì„ ì œì  ëŒ€ì‘
- ê°ê´€ì  ê²€ì¦ì„ í†µí•œ ì •ì±… ì‹ ë¢°ì„± í™•ë³´

### 4. **í•™ìˆ ì  ê¸°ì—¬**
- NAVIS íŒ¨í„´ì„ ì •í™•íˆ ë°˜ì˜í•˜ë©´ì„œë„ ê°œì„ ëœ ì„±ëŠ¥
- ì´ë¡ ì  ê·¼ê±°ë¥¼ í†µí•œ ì •ì±… ì œì–¸ì˜ íƒ€ë‹¹ì„±
- ê²€ì¦ëœ ë°©ë²•ë¡ ì„ í†µí•œ ì¬í˜„ ê°€ëŠ¥ì„±

## ğŸ“‹ ê²°ë¡ 

BDS ëª¨ë¸ì€ NAVIS ì§€í‘œ ëŒ€ë¹„ ë‹¤ìŒê³¼ ê°™ì€ ìš°ìˆ˜ì„±ì„ ë³´ì…ë‹ˆë‹¤:

1. **ì„±ëŠ¥ì  ìš°ìˆ˜ì„±**: í‰ê·  {performance['avg_improvement']:.2f}%ì˜ ê°œì„  íš¨ê³¼
2. **ì´ë¡ ì  ìš°ìˆ˜ì„±**: í•™ìˆ ì  ê·¼ê±°ë¥¼ í†µí•œ ê³¼í•™ì  ëª¨ë¸ë§
3. **ì‹¤ìš©ì  ìš°ìˆ˜ì„±**: ë†’ì€ ìƒê´€ê´€ê³„ì™€ ê²€ì¦ëœ ì‹ ë¢°ì„±
4. **ì˜ˆì¸¡ì  ìš°ìˆ˜ì„±**: NAVIS íŒ¨í„´ì„ ë”°ë¥´ëŠ” ë¯¸ë˜ ì˜ˆì¸¡ë ¥
5. **ì§€ì—­ë³„ ìš°ìˆ˜ì„±**: ì§€ì—­ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë¶„ì„

ì´ëŠ” **NAVISì˜ ì¥ì ì„ ìœ ì§€í•˜ë©´ì„œë„ ê°œì„ ëœ ì„±ëŠ¥**ì„ ì œê³µí•˜ëŠ” ìš°ìˆ˜í•œ ëª¨ë¸ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.
"""
    
    # ë³´ê³ ì„œ ì €ì¥
    with open('bds_superiority_analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… BDS ìš°ìˆ˜ì„± ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: bds_superiority_analysis_report.md")
    
    return report

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== BDS ëª¨ë¸ ìš°ìˆ˜ì„± ë¶„ì„ ===")
    print("ğŸ¯ ëª©í‘œ: NAVIS ì§€í‘œ ëŒ€ë¹„ BDS ëª¨ë¸ì˜ ê°œì„ ì  ë¶„ì„")
    
    # 1. ë°ì´í„° ë¡œë“œ
    bds_df, summary_df = load_data()
    if bds_df is None or summary_df is None:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # 2. ì„±ëŠ¥ì  ìš°ìˆ˜ì„± ë¶„ì„
    performance = analyze_performance_superiority(bds_df)
    
    # 3. ì´ë¡ ì  ìš°ìˆ˜ì„± ë¶„ì„
    theoretical = analyze_theoretical_superiority(bds_df)
    
    # 4. ì‹¤ìš©ì  ìš°ìˆ˜ì„± ë¶„ì„
    practical = analyze_practical_superiority(bds_df, summary_df)
    
    # 5. ì˜ˆì¸¡ì  ìš°ìˆ˜ì„± ë¶„ì„
    predictive = analyze_predictive_superiority(bds_df)
    
    # 6. ì§€ì—­ë³„ ìš°ìˆ˜ì„± ë¶„ì„
    regional = analyze_regional_superiority(bds_df)
    
    # 7. ìš°ìˆ˜ì„± ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    report = generate_superiority_report(performance, theoretical, practical, predictive, regional)
    
    print(f"\nâœ… BDS ëª¨ë¸ ìš°ìˆ˜ì„± ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š í•µì‹¬ ìš°ìˆ˜ì„±:")
    print(f"  - ì„±ëŠ¥ì : í‰ê·  {performance['avg_improvement']:.2f}% ê°œì„ ")
    print(f"  - ì´ë¡ ì : í•™ìˆ ì  ê·¼ê±° ê¸°ë°˜ ëª¨ë¸ë§")
    print(f"  - ì‹¤ìš©ì : ìƒê´€ê´€ê³„ {practical['avg_correlation']:.3f}, ê²€ì¦ì ìˆ˜ {practical['avg_validation_score']:.3f}")
    print(f"  - ì˜ˆì¸¡ì : íŠ¸ë Œë“œ ì˜ˆì¸¡ {predictive['avg_trend_prediction']:.3f}, ë³€ë™ì„± ì˜ˆì¸¡ {predictive['avg_volatility_prediction']:.3f}")
    print(f"  - ì§€ì—­ë³„: ë„ì‹œ {regional['city_improvement']:.2f}%, ë„ {regional['province_improvement']:.2f}%")

if __name__ == "__main__":
    main()
