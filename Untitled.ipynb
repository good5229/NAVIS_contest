{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58acb15-8dd5-457e-ac73-1b1e17d32a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 사용 연도: 2013–2022 (end_year=2022)\n",
      "[완료] 시계열 CSV: outputs_timeseries/bds_timeseries.csv\n",
      "[완료] 지도 HTML: outputs_timeseries/bds_choropleth.html\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "BDS 타임시리즈 + 지도(애니메이션) — 메타 호출 없이 Param/getList만 사용\n",
    "- 최근 10년 단위로 시도별 BDS 산출(PCA/동일/사용자 가중)\n",
    "- Plotly 코로플레스(연도 슬라이더) HTML 출력\n",
    "- GeoJSON의 시도명 필드가 '한글/영문' 어느 쪽이든 자동 매칭 (한글이면 매핑 금지)\n",
    "\n",
    "준비:\n",
    "1) pip install requests pandas numpy scikit-learn python-dotenv plotly\n",
    "2) .env 또는 OS 환경변수에 KOSIS_API_KEY 등록\n",
    "3) 시도 경계 GeoJSON 경로 지정(아래 __main__의 GEOJSON_PATH 수정)\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "# ---------------- 설정 ----------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"KOSIS_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"환경변수 KOSIS_API_KEY가 필요합니다. (.env에 추가하세요)\")\n",
    "\n",
    "OUTDIR = Path(\"./outputs_timeseries\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_PARAM = \"https://kosis.kr/openapi/Param/statisticsParameterData.do\"\n",
    "\n",
    "# 표 정의(공식 표ID, ITM_NM 키워드, 연간: prdSe='Y')\n",
    "TABLES = {\n",
    "    \"pc_grdp\":      {\"org\":\"101\",\"tbl\":\"DT_1C86\",     \"keyword\":\"1인당 지역내총생산\",\"prdSe\":\"Y\"},\n",
    "    \"pop_growth\":   {\"org\":\"101\",\"tbl\":\"DT_1YL20621\",\"keyword\":\"인구증가율\",\"prdSe\":\"Y\"},\n",
    "    \"elderly_rate\": {\"org\":\"101\",\"tbl\":\"DT_1YL20631\",\"keyword\":\"고령인구비율\",\"prdSe\":\"Y\"},\n",
    "    \"fiscal_indep\": {\"org\":\"101\",\"tbl\":\"DT_1YL20921\",\"keyword\":\"재정자립도\",\"prdSe\":\"Y\"},\n",
    "}\n",
    "\n",
    "# 이름 정규화(GeoJSON/표 간 표기차 흡수)\n",
    "def normalize_region_kor(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    rep = {\n",
    "        \"세종시\":\"세종특별자치시\",\n",
    "        \"제주도\":\"제주특별자치도\",\n",
    "        \"전북특별자치도\":\"전라북도\",   # 오래된 GeoJSON 호환용\n",
    "        \"강원특별자치도\":\"강원도\",\n",
    "        \"전남\":\"전라남도\",\"전북\":\"전라북도\",\n",
    "        \"경남\":\"경상남도\",\"경북\":\"경상북도\",\n",
    "        \"충남\":\"충청남도\",\"충북\":\"충청북도\",\n",
    "    }\n",
    "    return rep.get(s, s)\n",
    "\n",
    "KOR2ENG = {\n",
    "    \"서울특별시\":\"Seoul\",\"부산광역시\":\"Busan\",\"대구광역시\":\"Daegu\",\"인천광역시\":\"Incheon\",\n",
    "    \"광주광역시\":\"Gwangju\",\"대전광역시\":\"Daejeon\",\"울산광역시\":\"Ulsan\",\n",
    "    \"세종특별자치시\":\"Sejong\",\"경기도\":\"Gyeonggi-do\",\"강원도\":\"Gangwon-do\",\n",
    "    \"충청북도\":\"Chungcheongbuk-do\",\"충청남도\":\"Chungcheongnam-do\",\n",
    "    \"전라북도\":\"Jeollabuk-do\",\"전라남도\":\"Jeollanam-do\",\n",
    "    \"경상북도\":\"Gyeongsangbuk-do\",\"경상남도\":\"Gyeongsangnam-do\",\"제주특별자치도\":\"Jeju-do\"\n",
    "}\n",
    "\n",
    "# ----------- KOSIS 호출(Param/getList 전용, JSON 방어 포함) -----------\n",
    "def _get_json(url: str, params: Dict, retry=3, sleep=0.6):\n",
    "    \"\"\"\n",
    "    일부 상황에서 서버가 HTML/문자열을 200으로 반환할 수 있으므로\n",
    "    .json() 실패 시 진단 정보를 포함해 예외를 올림.\n",
    "    \"\"\"\n",
    "    last = None\n",
    "    headers = {\"Accept\":\"application/json\"}\n",
    "    for _ in range(retry):\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "        try:\n",
    "            data = r.json()\n",
    "            # KOSIS는 오류도 200으로 내려줄 수 있음\n",
    "            if isinstance(data, dict) and data.get(\"errMsg\"):\n",
    "                last = r\n",
    "            else:\n",
    "                return data\n",
    "        except Exception:\n",
    "            last = r\n",
    "        time.sleep(sleep)\n",
    "    if last is None:\n",
    "        raise RuntimeError(\"KOSIS 응답 실패(연결 불가).\")\n",
    "    ct = last.headers.get(\"Content-Type\")\n",
    "    preview = last.text[:200].replace(\"\\n\",\" \")\n",
    "    raise RuntimeError(f\"KOSIS JSON 파싱 실패: status={last.status_code}, \"\n",
    "                       f\"Content-Type={ct}, preview={preview}, params={params}\")\n",
    "\n",
    "def get_range_all_items(org:str, tbl:str, prdSe:str, y0:int, y1:int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    연도 구간 × 전지역(ALL) × 전항목(ALL) 조회 → 표준 컬럼만 반환\n",
    "    필드: region_name, period, value, (있으면 ITM_NM/ITM_ID)\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"method\":\"getList\",\"apiKey\":API_KEY,\"format\":\"json\",\"jsonVD\":\"Y\",\n",
    "        \"orgId\":org,\"tblId\":tbl,\"prdSe\":prdSe,\n",
    "        \"startPrdDe\":str(y0),\"endPrdDe\":str(y1),\n",
    "        \"objL1\":\"ALL\",\"itmId\":\"ALL\",\n",
    "        # outputFields 생략(표마다 상이; 전체 받아 안전 파싱)\n",
    "    }\n",
    "    data = _get_json(BASE_PARAM, params)\n",
    "    df = pd.DataFrame(data)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # 필수 컬럼 존재 확인\n",
    "    if \"DT\" not in df.columns or \"PRD_DE\" not in df.columns:\n",
    "        raise RuntimeError(\"KOSIS 응답에 DT 또는 PRD_DE 필드가 없습니다.\")\n",
    "    # 지역명 컬럼(C1_NM..)\n",
    "    region_col = next((c for c in [\"C1_NM\",\"C2_NM\",\"C3_NM\",\"C4_NM\",\"C5_NM\",\"C6_NM\",\"C7_NM\",\"C8_NM\"] if c in df.columns), None)\n",
    "    if not region_col:\n",
    "        raise RuntimeError(\"지역명 컬럼(C1_NM..C8_NM)을 찾지 못했습니다.\")\n",
    "\n",
    "    # 수치/연도형 변환 및 정리\n",
    "    df[\"DT\"] = pd.to_numeric(df[\"DT\"], errors=\"coerce\")\n",
    "    df[\"PRD_DE\"] = pd.to_numeric(df[\"PRD_DE\"], errors=\"coerce\")\n",
    "    df = df.rename(columns={region_col:\"region_name\",\"PRD_DE\":\"period\",\"DT\":\"value\"})\n",
    "    df = df.dropna(subset=[\"region_name\",\"period\",\"value\"])\n",
    "    # 합계행 제거\n",
    "    df = df[~df[\"region_name\"].isin({\"전국\",\"합계\",\"계\",\"전체\"})]\n",
    "\n",
    "    keep = [\"region_name\",\"period\",\"value\"]\n",
    "    if \"ITM_NM\" in df.columns: keep.append(\"ITM_NM\")\n",
    "    if \"ITM_ID\" in df.columns: keep.append(\"ITM_ID\")\n",
    "    return df[keep]\n",
    "\n",
    "def series_by_keyword(org:str, tbl:str, keyword:str, prdSe:str, y0:int, y1:int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ITM_NM이 있으면 contains(keyword)로 필터 → 지역×연도 평균\n",
    "    ITM_NM이 없으면 ITM_ID 평균(있으면 1차) → 지역×연도 평균 (폴백)\n",
    "    반환: region_name, period(int), value\n",
    "    \"\"\"\n",
    "    raw = get_range_all_items(org, tbl, prdSe, y0, y1)\n",
    "    if raw.empty:\n",
    "        return pd.DataFrame(columns=[\"region_name\",\"period\",\"value\"])\n",
    "\n",
    "    # 지역명 표준화\n",
    "    raw[\"region_name\"] = raw[\"region_name\"].astype(str).apply(normalize_region_kor)\n",
    "\n",
    "    if \"ITM_NM\" in raw.columns and raw[\"ITM_NM\"].notna().any():\n",
    "        sub = raw[raw[\"ITM_NM\"].astype(str).str.contains(keyword, na=False)]\n",
    "        if sub.empty:\n",
    "            cand = \", \".join(sorted(map(str, raw[\"ITM_NM\"].dropna().unique()))[:10])\n",
    "            raise RuntimeError(f\"'{keyword}' 항목을 찾지 못했습니다(표 {tbl}). 가능한 예: {cand}\")\n",
    "        g = sub.groupby([\"region_name\",\"period\"], as_index=False)[\"value\"].mean()\n",
    "    else:\n",
    "        grp = [\"region_name\",\"period\"] + ([\"ITM_ID\"] if \"ITM_ID\" in raw.columns else [])\n",
    "        tmp = raw.groupby(grp, as_index=False)[\"value\"].mean()\n",
    "        if \"ITM_ID\" in tmp.columns:\n",
    "            tmp = tmp.groupby([\"region_name\",\"period\"], as_index=False)[\"value\"].mean()\n",
    "        g = tmp\n",
    "\n",
    "    g[\"period\"] = g[\"period\"].astype(int)\n",
    "    return g[[\"region_name\",\"period\",\"value\"]]\n",
    "\n",
    "# ---------- BDS 계산 ----------\n",
    "def compute_bds_one_year(df_year: pd.DataFrame,\n",
    "                         cols: List[str],\n",
    "                         weight_mode: str = \"pca\",\n",
    "                         custom: Optional[Dict[str,float]] = None) -> Tuple[pd.DataFrame, Dict[str,float]]:\n",
    "    \"\"\"\n",
    "    df_year: columns=[region_name, period] + cols\n",
    "    - elderly_rate는 부담방향이므로 부호 반전 후 표준화\n",
    "    - weight_mode: \"pca\" | \"equal\" | \"custom\"\n",
    "    \"\"\"\n",
    "    X = df_year[cols].astype(float).copy()\n",
    "\n",
    "    X_adj = X.copy()\n",
    "    if \"elderly_rate\" in X_adj.columns:\n",
    "        X_adj[\"elderly_rate\"] = -X_adj[\"elderly_rate\"]\n",
    "\n",
    "    Z = StandardScaler().fit_transform(X_adj.values)\n",
    "\n",
    "    if weight_mode == \"equal\":\n",
    "        w = np.full(len(cols), 1/len(cols), dtype=float)\n",
    "    elif weight_mode == \"custom\":\n",
    "        if not custom:\n",
    "            raise ValueError(\"custom 가중치 dict가 필요합니다.\")\n",
    "        w = np.array([custom[c] for c in cols], dtype=float)\n",
    "        s = w.sum()\n",
    "        if s == 0:\n",
    "            raise ValueError(\"custom 가중치의 합이 0입니다.\")\n",
    "        w = w / s\n",
    "    else:  # \"pca\"\n",
    "        p = PCA(n_components=1, random_state=42).fit(Z)\n",
    "        load = np.abs(p.components_[0])\n",
    "        w = load / load.sum()\n",
    "\n",
    "    df_out = df_year.copy()\n",
    "    df_out[\"BDS\"] = (Z * w).sum(axis=1)\n",
    "    weights = {c: float(w[i]) for i, c in enumerate(cols)}\n",
    "    return df_out, weights\n",
    "\n",
    "# ---------- 메인: 최근 10년 시계열 + 지도 ----------\n",
    "def build_timeseries_and_map(weight_mode=\"pca\",\n",
    "                             custom_weights: Optional[Dict[str,float]] = None,\n",
    "                             min_year: int = 2000,\n",
    "                             geojson_path: str = \"./skorea-provinces-2018-geo.json\",\n",
    "                             geojson_name_field: Optional[str] = None,\n",
    "                             out_csv: str = \"bds_timeseries.csv\",\n",
    "                             out_html: str = \"bds_choropleth.html\"):\n",
    "    \"\"\"\n",
    "    1) 각 표에서 넓은 구간(min_year~2100)을 한 번 호출하여 이용 가능한 연도 목록 확보\n",
    "    2) 4지표 연도 교집합의 최댓값을 end_year로 채택 → 최근 10년(end_year-9 ~ end_year)\n",
    "    3) 연도별로 4표 inner join → BDS 산출\n",
    "    4) CSV/HTML 저장\n",
    "    \"\"\"\n",
    "    # 1) 넓은 구간에서 지표별 연도 확보\n",
    "    avail = {}\n",
    "    wide_y0, wide_y1 = min_year, 2100\n",
    "    for key, spec in TABLES.items():\n",
    "        dfw = series_by_keyword(spec[\"org\"], spec[\"tbl\"], spec[\"keyword\"], spec[\"prdSe\"], wide_y0, wide_y1)\n",
    "        years = sorted(dfw[\"period\"].unique().tolist())\n",
    "        if not years:\n",
    "            raise RuntimeError(f\"{key} 표에서 사용 가능한 연도가 없습니다. 표ID/항목/주기를 확인하세요.\")\n",
    "        avail[key] = years\n",
    "\n",
    "    # 2) 4지표 연도 교집합 → end_year 및 최근 10년\n",
    "    inter = set(avail[\"pc_grdp\"])\n",
    "    for k in [\"pop_growth\",\"elderly_rate\",\"fiscal_indep\"]:\n",
    "        inter &= set(avail[k])\n",
    "    if not inter:\n",
    "        raise RuntimeError(\"4개 지표의 연도 교집합이 없습니다. 표/항목/주기를 확인하세요.\")\n",
    "    end_year = max(inter)\n",
    "    years = [y for y in range(end_year-9, end_year+1) if y in inter]\n",
    "    if not years:\n",
    "        raise RuntimeError(\"최근 10년을 구성할 연도가 부족합니다.\")\n",
    "    print(f\"[INFO] 사용 연도: {years[0]}–{years[-1]} (end_year={end_year})\")\n",
    "\n",
    "    # 3) 연도별 수집·병합\n",
    "    frames = []\n",
    "    for y in years:\n",
    "        parts = []\n",
    "        for col, spec in TABLES.items():\n",
    "            df = series_by_keyword(spec[\"org\"], spec[\"tbl\"], spec[\"keyword\"], spec[\"prdSe\"], y, y)\n",
    "            df = df.rename(columns={\"value\": col})\n",
    "            parts.append(df[[\"region_name\",\"period\",col]])\n",
    "        one = parts[0]\n",
    "        for p in parts[1:]:\n",
    "            one = one.merge(p, on=[\"region_name\",\"period\"], how=\"inner\")\n",
    "        if not one.empty:\n",
    "            frames.append(one)\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"연도별 병합 결과가 비었습니다.\")\n",
    "    base_ts = pd.concat(frames, ignore_index=True)\n",
    "    base_ts[\"region_name\"] = base_ts[\"region_name\"].apply(normalize_region_kor)\n",
    "\n",
    "    # 4) 연도별 BDS\n",
    "    cols = [\"pc_grdp\",\"pop_growth\",\"elderly_rate\",\"fiscal_indep\"]\n",
    "    bds_frames, weights_by_year = [], []\n",
    "    for y, dfy in base_ts.groupby(\"period\"):\n",
    "        scored, w = compute_bds_one_year(dfy, cols, weight_mode, custom_weights)\n",
    "        bds_frames.append(scored)\n",
    "        w[\"period\"] = int(y)\n",
    "        weights_by_year.append(w)\n",
    "\n",
    "    bds_ts = pd.concat(bds_frames, ignore_index=True)\n",
    "    bds_ts = bds_ts.sort_values([\"period\",\"BDS\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # 5) 저장\n",
    "    OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "    bds_ts.to_csv(OUTDIR/out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    with open(OUTDIR/\"weights_by_year.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "        json.dump({\"weight_mode\":weight_mode,\n",
    "                   \"weights_by_year\":weights_by_year,\n",
    "                   \"years\":years,\n",
    "                   \"end_year\":int(end_year)}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 6) 지도(연도 슬라이더 코로플레스) — 한글/영문 자동 매칭 패치\n",
    "    with open(geojson_path,\"r\",encoding=\"utf-8\") as f:\n",
    "        gj = json.load(f)\n",
    "\n",
    "    # 시도명 필드 자동판별: 'CTP_KOR_NM'(한글) 우선, 없으면 'name'\n",
    "    if geojson_name_field is None:\n",
    "        sample_props = gj[\"features\"][0][\"properties\"]\n",
    "        if \"CTP_KOR_NM\" in sample_props:\n",
    "            geojson_name_field = \"CTP_KOR_NM\"\n",
    "        elif \"name\" in sample_props:\n",
    "            geojson_name_field = \"name\"\n",
    "        else:\n",
    "            raise KeyError(f\"GeoJSON에서 시도명 필드를 찾지 못했습니다. keys={list(sample_props.keys())}\")\n",
    "\n",
    "    # 'name'이 한글인지/영문인지 감지\n",
    "    def _has_hangul(s: str) -> bool:\n",
    "        s = str(s)\n",
    "        return any(\"\\uac00\" <= ch <= \"\\ud7a3\" for ch in s)\n",
    "\n",
    "    name_samples = [feat[\"properties\"][geojson_name_field] for feat in gj[\"features\"]]\n",
    "    uses_korean_names = any(_has_hangul(v) for v in name_samples)\n",
    "\n",
    "    df_map = bds_ts.copy()\n",
    "\n",
    "    if geojson_name_field == \"CTP_KOR_NM\":\n",
    "        # 한글 시도명\n",
    "        df_map[\"loc_key\"] = df_map[\"region_name\"].astype(str)\n",
    "        featureidkey = \"properties.CTP_KOR_NM\"\n",
    "\n",
    "    elif geojson_name_field == \"name\":\n",
    "        if uses_korean_names:\n",
    "            # name이 한글 → 영어 매핑 금지, 그대로 매칭\n",
    "            df_map[\"loc_key\"] = df_map[\"region_name\"].astype(str)\n",
    "        else:\n",
    "            # name이 영문 → 한→영 매핑\n",
    "            df_map[\"loc_key\"] = df_map[\"region_name\"].map(lambda x: KOR2ENG.get(x, x))\n",
    "        featureidkey = \"properties.name\"\n",
    "\n",
    "    else:\n",
    "        # 기타 필드: region_name 그대로 매칭\n",
    "        df_map[\"loc_key\"] = df_map[\"region_name\"].astype(str)\n",
    "        featureidkey = f\"properties.{geojson_name_field}\"\n",
    "\n",
    "    # 매칭 검증: GeoJSON에 없는 지역명 출력\n",
    "    gj_name_set = {feat[\"properties\"][geojson_name_field] for feat in gj[\"features\"]}\n",
    "    missing = sorted(set(df_map[\"loc_key\"]) - gj_name_set)\n",
    "    if missing:\n",
    "        print(\"⚠ 매칭 실패 지역명(GeoJSON에 없음):\", missing)\n",
    "\n",
    "    fig = px.choropleth(\n",
    "        df_map,\n",
    "        geojson=gj,\n",
    "        featureidkey=featureidkey,\n",
    "        locations=\"loc_key\",\n",
    "        color=\"BDS\",\n",
    "        animation_frame=\"period\",\n",
    "        color_continuous_scale=\"Viridis\",\n",
    "        hover_name=\"region_name\",\n",
    "        hover_data={\"pc_grdp\":\":.0f\",\"pop_growth\":\":.2f\",\"elderly_rate\":\":.2f\",\n",
    "                    \"fiscal_indep\":\":.1f\",\"loc_key\":False}\n",
    "    )\n",
    "    fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "    fig.update_layout(title=f\"BDS 최근 10년(가중치: {weight_mode})\",\n",
    "                      margin=dict(l=0, r=0, t=45, b=0))\n",
    "    out_html_path = OUTDIR/out_html\n",
    "    fig.write_html(str(out_html_path), include_plotlyjs=\"cdn\")\n",
    "\n",
    "    print(f\"[완료] 시계열 CSV: {OUTDIR/out_csv}\")\n",
    "    print(f\"[완료] 지도 HTML: {out_html_path}\")\n",
    "\n",
    "# ---- 실행 예시 ----\n",
    "if __name__ == \"__main__\":\n",
    "    # 준비한 시도 경계 GeoJSON 경로 지정\n",
    "    # (예: 업로드한 파일명)\n",
    "    GEOJSON_PATH = \"./skorea-provinces-2018-geo.json\"\n",
    "\n",
    "    build_timeseries_and_map(\n",
    "        weight_mode=\"pca\",          # \"equal\" 또는 \"custom\"도 가능\n",
    "        custom_weights=None,        # 예: {\"pc_grdp\":0.35,\"pop_growth\":0.25,\"elderly_rate\":0.15,\"fiscal_indep\":0.25}\n",
    "        min_year=2000,\n",
    "        geojson_path=GEOJSON_PATH,\n",
    "        geojson_name_field=None,    # 수동지정하려면 \"name\" 또는 \"CTP_KOR_NM\"\n",
    "        out_csv=\"bds_timeseries.csv\",\n",
    "        out_html=\"bds_choropleth.html\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241aa55-0038-4c14-92ed-4dced6cb6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (navis)",
   "language": "python",
   "name": "navis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
