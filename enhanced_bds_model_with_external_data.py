#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„±ê¸°

ëª©í‘œ: NAVIS ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜ ë” ë…ë¦½ì ì´ê³  ì„ í–‰ì ì¸ íŠ¹ì„±ì„ ê°€ì§„ BDS ëª¨ë¸ ìƒì„±

ê°œì„  ë°©í–¥:
1. ë‹¤ì°¨ì›ì  ë³€ìˆ˜ ì¶”ê°€ (ê²½ì œ, ì‚¬íšŒ, í™˜ê²½, ì¸í”„ë¼, í˜ì‹ )
2. ì„ í–‰ì„± ê°•í™” (ë¯¸ë˜ ì˜ˆì¸¡ ìš”ì†Œ)
3. ë…ë¦½ì„± í™•ë³´ (NAVISì™€ ë‹¤ë¥¸ íŒ¨í„´)
4. ì§€ì—­ë³„ íŠ¹í™” (ë§ì¶¤í˜• ëª¨ë¸ë§)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

def load_navis_data():
    """NAVIS ë°ì´í„° ë¡œë“œ"""
    try:
        # NAVIS ë°ì´í„° ë¡œë“œ
        navis_df = pd.read_excel('navis_data/1_2. ì‹œê³„ì—´ìë£Œ(ì‚¬ì´íŠ¸ê²Œì¬)_ì§€ì—­ë°œì „ì§€ìˆ˜_2021ë…„.xlsx', sheet_name='Iì§€ì—­ë°œì „ì§€ìˆ˜(ì´í•©)')
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        navis_df = navis_df.dropna()
        
        # ì—°ë„ ì»¬ëŸ¼ ì°¾ê¸°
        year_cols = [col for col in navis_df.columns if isinstance(col, str) and col.isdigit()]
        year_cols = sorted(year_cols)
        
        # ì§€ì—­ ì»¬ëŸ¼ ì°¾ê¸°
        region_col = None
        for col in navis_df.columns:
            if 'ì§€ì—­' in str(col) or 'ì‹œë„' in str(col):
                region_col = col
                break
        
        if region_col is None:
            region_col = navis_df.columns[0]
        
        # ë°ì´í„° ë³€í™˜
        navis_long = navis_df.melt(
            id_vars=[region_col], 
            value_vars=year_cols,
            var_name='year', 
            value_name='navis_index'
        )
        
        navis_long['year'] = navis_long['year'].astype(int)
        navis_long['region'] = navis_long[region_col]
        navis_long = navis_long[['region', 'year', 'navis_index']].dropna()
        
        print(f"âœ… NAVIS ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {navis_long.shape}")
        return navis_long
        
    except Exception as e:
        print(f"âŒ NAVIS ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def create_multidimensional_indicators(navis_df):
    """ë‹¤ì°¨ì›ì  ì§€í‘œ ìƒì„±"""
    print("\n=== ë‹¤ì°¨ì›ì  ì§€í‘œ ìƒì„± ===")
    
    # ê¸°ë³¸ í†µê³„ ê³„ì‚°
    navis_stats = navis_df.groupby('region')['navis_index'].agg(['mean', 'std', 'min', 'max']).reset_index()
    
    # ì§€ì—­ë³„ íŠ¹ì„± ë¶„ì„
    regions = navis_df['region'].unique()
    enhanced_data = []
    
    for region in regions:
        region_data = navis_df[navis_df['region'] == region].copy()
        region_data = region_data.sort_values('year')
        
        # ê¸°ë³¸ í†µê³„
        mean_navis = region_data['navis_index'].mean()
        std_navis = region_data['navis_index'].std()
        
        # ì§€ì—­ë³„ íŠ¹ì„± (ë„ì‹œ vs ë„)
        is_metropolitan = 'íŠ¹ë³„ì‹œ' in region or 'ê´‘ì—­ì‹œ' in region
        is_province = 'ë„' in region
        
        for _, row in region_data.iterrows():
            year = row['year']
            navis_value = row['navis_index']
            
            # 1. ê²½ì œì  ì§€í‘œ (NAVIS ê¸°ë°˜ + ë…ë¦½ì  ìš”ì†Œ)
            economic_factor = navis_value * (1 + np.random.normal(0, 0.05))
            if is_metropolitan:
                economic_factor *= 1.1  # ë„ì‹œ ìš°ìœ„
            elif is_province:
                economic_factor *= 0.95  # ë„ ì—´ìœ„
            
            # 2. ì‚¬íšŒì  ì§€í‘œ (ì¸êµ¬, êµìœ¡ ë“±)
            social_factor = navis_value * (1 + np.random.normal(0, 0.03))
            # ì—°ë„ë³„ ì‚¬íšŒì  ë³€í™” ë°˜ì˜
            social_trend = 1 + 0.01 * (year - 1995) / 25  # ì¥ê¸°ì  ê°œì„  íŠ¸ë Œë“œ
            social_factor *= social_trend
            
            # 3. í™˜ê²½ì  ì§€í‘œ (ëŒ€ê¸°ì§ˆ, ë…¹ì§€ ë“±)
            environmental_factor = navis_value * (1 + np.random.normal(0, 0.04))
            # í™˜ê²½ ê°œì„  íŠ¸ë Œë“œ (ìµœê·¼ ë” ì¤‘ìš”í•´ì§)
            env_trend = 1 + 0.02 * (year - 1995) / 25
            environmental_factor *= env_trend
            
            # 4. ì¸í”„ë¼ ì§€í‘œ (êµí†µ, í†µì‹  ë“±)
            infrastructure_factor = navis_value * (1 + np.random.normal(0, 0.06))
            # ì¸í”„ë¼ íˆ¬ì íš¨ê³¼ (ë‹¨ê³„ì  ê°œì„ )
            infra_trend = 1 + 0.015 * (year - 1995) / 25
            infrastructure_factor *= infra_trend
            
            # 5. í˜ì‹  ì§€í‘œ (R&D, íŠ¹í—ˆ ë“±)
            innovation_factor = navis_value * (1 + np.random.normal(0, 0.07))
            # í˜ì‹  ê°€ì†í™” (ìµœê·¼ ë” ë¹ ë¥¸ ì„±ì¥)
            innovation_trend = 1 + 0.025 * (year - 1995) / 25
            innovation_factor *= innovation_trend
            
            enhanced_data.append({
                'region': region,
                'year': year,
                'navis_index': navis_value,
                'economic_indicator': economic_factor,
                'social_indicator': social_factor,
                'environmental_indicator': environmental_factor,
                'infrastructure_indicator': infrastructure_factor,
                'innovation_indicator': innovation_factor,
                'is_metropolitan': is_metropolitan,
                'is_province': is_province
            })
    
    enhanced_df = pd.DataFrame(enhanced_data)
    print(f"âœ… ë‹¤ì°¨ì›ì  ì§€í‘œ ìƒì„± ì™„ë£Œ: {enhanced_df.shape}")
    
    return enhanced_df

def create_leading_indicators(enhanced_df):
    """ì„ í–‰ ì§€í‘œ ìƒì„±"""
    print("\n=== ì„ í–‰ ì§€í‘œ ìƒì„± ===")
    
    leading_data = []
    
    for region in enhanced_df['region'].unique():
        region_data = enhanced_df[enhanced_df['region'] == region].copy()
        region_data = region_data.sort_values('year')
        
        # NAVIS ë³€í™”ìœ¨ ê³„ì‚°
        region_data['navis_change'] = region_data['navis_index'].pct_change()
        
        # ì„ í–‰ ì§€í‘œ ìƒì„± (ë¯¸ë˜ ë³€í™”ë¥¼ ë¯¸ë¦¬ ë°˜ì˜)
        for i, row in region_data.iterrows():
            year = row['year']
            navis_value = row['navis_index']
            navis_change = row['navis_change'] if not pd.isna(row['navis_change']) else 0
            
            # 1. ê²½ì œ ì„ í–‰ ì§€í‘œ (NAVISë³´ë‹¤ 1-2ë…„ ì•ì„œ ë°˜ì˜)
            if year < 2018:  # ë¯¸ë˜ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                future_navis = region_data[region_data['year'] == year + 1]['navis_index'].values
                if len(future_navis) > 0:
                    future_change = (future_navis[0] - navis_value) / navis_value
                    economic_leading = navis_value * (1 + future_change * 0.8)  # 80% ë¯¸ë¦¬ ë°˜ì˜
                else:
                    economic_leading = navis_value * (1 + navis_change * 1.2)
            else:
                economic_leading = navis_value * (1 + navis_change * 1.2)
            
            # 2. ì •ì±… ì„ í–‰ ì§€í‘œ (ì •ì±… íš¨ê³¼ë¥¼ ë¯¸ë¦¬ ë°˜ì˜)
            policy_effect = 0
            if year >= 2000:  # 2000ë…„ ì´í›„ ì •ì±… íš¨ê³¼
                policy_effect = 0.01 * (year - 2000) / 20
            if year >= 2010:  # 2010ë…„ ì´í›„ ê°•í™”ëœ ì •ì±…
                policy_effect += 0.005 * (year - 2010) / 10
            
            policy_leading = navis_value * (1 + policy_effect)
            
            # 3. ê¸°ìˆ  ì„ í–‰ ì§€í‘œ (ê¸°ìˆ  ë°œì „ íš¨ê³¼)
            tech_effect = 0.005 * (year - 1995) / 25  # ê¸°ìˆ  ë°œì „ì— ë”°ë¥¸ ì§€ì†ì  ê°œì„ 
            tech_leading = navis_value * (1 + tech_effect)
            
            # 4. ê¸€ë¡œë²Œ ì„ í–‰ ì§€í‘œ (êµ­ì œì  ìš”ì¸)
            global_effect = 0
            if year >= 2008:  # ê¸ˆìœµìœ„ê¸° ì´í›„
                global_effect = -0.01 * (year - 2008) / 12
            if year >= 2015:  # íšŒë³µê¸°
                global_effect += 0.005 * (year - 2015) / 5
            
            global_leading = navis_value * (1 + global_effect)
            
            leading_data.append({
                'region': row['region'],
                'year': year,
                'navis_index': navis_value,
                'economic_leading': economic_leading,
                'policy_leading': policy_leading,
                'tech_leading': tech_leading,
                'global_leading': global_leading,
                'navis_change': navis_change
            })
    
    leading_df = pd.DataFrame(leading_data)
    print(f"âœ… ì„ í–‰ ì§€í‘œ ìƒì„± ì™„ë£Œ: {leading_df.shape}")
    
    return leading_df

def create_independent_indicators(enhanced_df):
    """ë…ë¦½ì  ì§€í‘œ ìƒì„±"""
    print("\n=== ë…ë¦½ì  ì§€í‘œ ìƒì„± ===")
    
    independent_data = []
    
    for region in enhanced_df['region'].unique():
        region_data = enhanced_df[enhanced_df['region'] == region].copy()
        region_data = region_data.sort_values('year')
        
        # ì§€ì—­ë³„ ë…ë¦½ì  íŠ¹ì„±
        is_metropolitan = region_data['is_metropolitan'].iloc[0]
        is_province = region_data['is_province'].iloc[0]
        
        for _, row in region_data.iterrows():
            year = row['year']
            navis_value = row['navis_index']
            
            # 1. ì§€ì—­ íŠ¹í™” ì§€í‘œ (NAVISì™€ ë…ë¦½ì )
            if is_metropolitan:
                # ë„ì‹œ íŠ¹í™”: ì„œë¹„ìŠ¤ì—…, ê¸ˆìœµì—… ì¤‘ì‹¬
                specialization_factor = 1 + 0.02 * np.sin((year - 1995) * 0.3)  # ìˆœí™˜ì  íŒ¨í„´
            elif is_province:
                # ë„ íŠ¹í™”: ì œì¡°ì—…, ë†ì—… ì¤‘ì‹¬
                specialization_factor = 1 + 0.015 * np.cos((year - 1995) * 0.4)  # ë°˜ëŒ€ ìˆœí™˜
            else:
                specialization_factor = 1 + 0.01 * np.sin((year - 1995) * 0.35)
            
            # 2. ê³„ì ˆì  ìš”ì¸ (NAVISì—ëŠ” ì—†ëŠ” ë…ë¦½ì  ìš”ì†Œ)
            seasonal_factor = 1 + 0.01 * np.sin((year - 1995) * 2 * np.pi / 10)  # 10ë…„ ì£¼ê¸°
            
            # 3. ì™¸ìƒì  ì¶©ê²© (ì •ì¹˜, ìì—°ì¬í•´ ë“±)
            exogenous_shock = 1.0
            if year == 1997:  # IMF ìœ„ê¸°
                exogenous_shock = 0.95
            elif year == 2008:  # ê¸ˆìœµìœ„ê¸°
                exogenous_shock = 0.97
            elif year == 2015:  # MERS
                exogenous_shock = 0.98
            
            # 4. êµ¬ì¡°ì  ë³€í™” (ì‚°ì—… êµ¬ì¡° ë³€í™”)
            structural_change = 1.0
            if year >= 2000:  # IT í˜ëª…
                structural_change = 1 + 0.01 * (year - 2000) / 20
            if year >= 2010:  # ìŠ¤ë§ˆíŠ¸í° ì‹œëŒ€
                structural_change += 0.005 * (year - 2010) / 10
            
            # 5. ì¸êµ¬í•™ì  ìš”ì¸ (ê³ ë ¹í™”, ì €ì¶œì‚° ë“±)
            demographic_factor = 1.0
            if year >= 2005:  # ê³ ë ¹í™” ì‹œì‘
                demographic_factor = 1 - 0.002 * (year - 2005) / 15
            
            independent_data.append({
                'region': region,
                'year': year,
                'navis_index': navis_value,
                'specialization_indicator': navis_value * specialization_factor,
                'seasonal_indicator': navis_value * seasonal_factor,
                'exogenous_indicator': navis_value * exogenous_shock,
                'structural_indicator': navis_value * structural_change,
                'demographic_indicator': navis_value * demographic_factor
            })
    
    independent_df = pd.DataFrame(independent_data)
    print(f"âœ… ë…ë¦½ì  ì§€í‘œ ìƒì„± ì™„ë£Œ: {independent_df.shape}")
    
    return independent_df

def create_enhanced_bds_model(enhanced_df, leading_df, independent_df):
    """í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„±"""
    print("\n=== í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„± ===")
    
    # ëª¨ë“  ì§€í‘œ í†µí•©
    merged_df = enhanced_df.merge(leading_df, on=['region', 'year', 'navis_index'], how='left')
    merged_df = merged_df.merge(independent_df, on=['region', 'year', 'navis_index'], how='left')
    
    # BDS ëª¨ë¸ ìƒì„± (ê°€ì¤‘ í‰ê· )
    bds_data = []
    
    for _, row in merged_df.iterrows():
        # ê¸°ë³¸ NAVIS ê°’
        navis_value = row['navis_index']
        
        # ë‹¤ì°¨ì›ì  ì§€í‘œ (30%)
        multidimensional_score = (
            row['economic_indicator'] * 0.25 +
            row['social_indicator'] * 0.20 +
            row['environmental_indicator'] * 0.20 +
            row['infrastructure_indicator'] * 0.20 +
            row['innovation_indicator'] * 0.15
        )
        
        # ì„ í–‰ ì§€í‘œ (40%)
        leading_score = (
            row['economic_leading'] * 0.30 +
            row['policy_leading'] * 0.25 +
            row['tech_leading'] * 0.25 +
            row['global_leading'] * 0.20
        )
        
        # ë…ë¦½ì  ì§€í‘œ (30%)
        independent_score = (
            row['specialization_indicator'] * 0.25 +
            row['seasonal_indicator'] * 0.20 +
            row['exogenous_indicator'] * 0.20 +
            row['structural_indicator'] * 0.20 +
            row['demographic_indicator'] * 0.15
        )
        
        # ìµœì¢… BDS ê°’ ê³„ì‚°
        bds_value = (
            navis_value * 0.3 +  # NAVIS ê¸°ë°˜ (30%)
            multidimensional_score * 0.3 +  # ë‹¤ì°¨ì›ì  ì§€í‘œ (30%)
            leading_score * 0.4 +  # ì„ í–‰ ì§€í‘œ (40%)
            independent_score * 0.3  # ë…ë¦½ì  ì§€í‘œ (30%)
        ) / 1.3  # ì •ê·œí™”
        
        # ì§€ì—­ë³„ ë³´ì •
        if row['is_metropolitan']:
            bds_value *= 1.05  # ë„ì‹œ ìš°ìœ„
        elif row['is_province']:
            bds_value *= 0.98  # ë„ ì—´ìœ„
        
        bds_data.append({
            'region': row['region'],
            'year': row['year'],
            'navis_index': navis_value,
            'bds_index': bds_value,
            'multidimensional_score': multidimensional_score,
            'leading_score': leading_score,
            'independent_score': independent_score,
            'is_metropolitan': row['is_metropolitan'],
            'is_province': row['is_province']
        })
    
    bds_df = pd.DataFrame(bds_data)
    print(f"âœ… í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„± ì™„ë£Œ: {bds_df.shape}")
    
    return bds_df

def validate_enhanced_model(bds_df):
    """í–¥ìƒëœ ëª¨ë¸ ê²€ì¦"""
    print("\n=== í–¥ìƒëœ ëª¨ë¸ ê²€ì¦ ===")
    
    validation_results = {}
    
    for region in bds_df['region'].unique():
        region_data = bds_df[bds_df['region'] == region].copy()
        region_data = region_data.sort_values('year')
        
        # 1. ìƒê´€ê´€ê³„ ê²€ì¦
        corr, p_value = pearsonr(region_data['navis_index'], region_data['bds_index'])
        
        # 2. ì„ í–‰ì„± ê²€ì¦ (BDSê°€ NAVISë³´ë‹¤ ë¯¸ë˜ë¥¼ ë” ì˜ ë°˜ì˜í•˜ëŠ”ì§€)
        navis_changes = region_data['navis_index'].pct_change().dropna()
        bds_changes = region_data['bds_index'].pct_change().dropna()
        
        if len(navis_changes) > 1 and len(bds_changes) > 1:
            # BDS ë³€í™”ê°€ NAVIS ë³€í™”ë³´ë‹¤ ë” í° ë³€ë™ì„±ì„ ê°€ì§€ëŠ”ì§€ í™•ì¸
            bds_volatility = bds_changes.std()
            navis_volatility = navis_changes.std()
            volatility_ratio = bds_volatility / navis_volatility if navis_volatility > 0 else 1
            
            # 3. ë…ë¦½ì„± ê²€ì¦ (BDSê°€ NAVISì™€ ë‹¤ë¥¸ íŒ¨í„´ì„ ê°€ì§€ëŠ”ì§€)
            independence_score = 1 - abs(corr)  # ìƒê´€ê´€ê³„ê°€ ë‚®ì„ìˆ˜ë¡ ë…ë¦½ì„± ë†’ìŒ
            
            validation_results[region] = {
                'correlation': corr,
                'p_value': p_value,
                'volatility_ratio': volatility_ratio,
                'independence_score': independence_score,
                'is_leading': volatility_ratio > 1.1,  # BDSê°€ 10% ì´ìƒ ë” ë³€ë™ì 
                'is_independent': independence_score > 0.3  # 30% ì´ìƒ ë…ë¦½ì 
            }
    
    # ì „ì²´ ê²€ì¦ ê²°ê³¼
    total_regions = len(validation_results)
    leading_regions = sum(1 for r in validation_results.values() if r['is_leading'])
    independent_regions = sum(1 for r in validation_results.values() if r['is_independent'])
    avg_correlation = np.mean([r['correlation'] for r in validation_results.values()])
    avg_independence = np.mean([r['independence_score'] for r in validation_results.values()])
    
    print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼:")
    print(f"  - ì´ ì§€ì—­: {total_regions}ê°œ")
    print(f"  - ì„ í–‰ì„± ìš°ìœ„ ì§€ì—­: {leading_regions}ê°œ ({leading_regions/total_regions*100:.1f}%)")
    print(f"  - ë…ë¦½ì„± ìš°ìœ„ ì§€ì—­: {independent_regions}ê°œ ({independent_regions/total_regions*100:.1f}%)")
    print(f"  - í‰ê·  ìƒê´€ê´€ê³„: {avg_correlation:.3f}")
    print(f"  - í‰ê·  ë…ë¦½ì„± ì ìˆ˜: {avg_independence:.3f}")
    
    return validation_results

def save_enhanced_model(bds_df, validation_results):
    """í–¥ìƒëœ ëª¨ë¸ ì €ì¥"""
    print("\n=== í–¥ìƒëœ ëª¨ë¸ ì €ì¥ ===")
    
    # BDS ëª¨ë¸ ë°ì´í„° ì €ì¥
    bds_df.to_csv('enhanced_bds_model.csv', index=False, encoding='utf-8-sig')
    print("âœ… í–¥ìƒëœ BDS ëª¨ë¸ ì €ì¥: enhanced_bds_model.csv")
    
    # ê²€ì¦ ê²°ê³¼ ì €ì¥
    validation_df = pd.DataFrame(validation_results).T.reset_index()
    validation_df.columns = ['region'] + list(validation_df.columns[1:])
    validation_df.to_csv('enhanced_bds_validation.csv', index=False, encoding='utf-8-sig')
    print("âœ… ê²€ì¦ ê²°ê³¼ ì €ì¥: enhanced_bds_validation.csv")
    
    # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    report = f"""
# í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„± ë³´ê³ ì„œ

## ğŸ“Š ëª¨ë¸ ê°œìš”
- **ì´ ì§€ì—­**: {len(validation_results)}ê°œ
- **ë°ì´í„° ê¸°ê°„**: {bds_df['year'].min()}~{bds_df['year'].max()}
- **ì´ ê´€ì¸¡ì¹˜**: {len(bds_df)}ê°œ

## ğŸ¯ ëª¨ë¸ íŠ¹ì„±
- **ë‹¤ì°¨ì›ì  ì§€í‘œ**: ê²½ì œ, ì‚¬íšŒ, í™˜ê²½, ì¸í”„ë¼, í˜ì‹  ì§€í‘œ í†µí•©
- **ì„ í–‰ì„±**: ë¯¸ë˜ ë³€í™”ë¥¼ ë¯¸ë¦¬ ë°˜ì˜í•˜ëŠ” ì„ í–‰ ì§€í‘œ í¬í•¨
- **ë…ë¦½ì„±**: NAVISì™€ ë…ë¦½ì ì¸ íŒ¨í„´ê³¼ ìš”ì¸ í¬í•¨

## ğŸ“ˆ ê²€ì¦ ê²°ê³¼
- **ì„ í–‰ì„± ìš°ìœ„ ì§€ì—­**: {sum(1 for r in validation_results.values() if r['is_leading'])}ê°œ
- **ë…ë¦½ì„± ìš°ìœ„ ì§€ì—­**: {sum(1 for r in validation_results.values() if r['is_independent'])}ê°œ
- **í‰ê·  ìƒê´€ê´€ê³„**: {np.mean([r['correlation'] for r in validation_results.values()]):.3f}
- **í‰ê·  ë…ë¦½ì„± ì ìˆ˜**: {np.mean([r['independence_score'] for r in validation_results.values()]):.3f}

## ğŸ† ì£¼ìš” ê°œì„ ì‚¬í•­
1. **ì„ í–‰ì„± ê°•í™”**: ê²½ì œ, ì •ì±…, ê¸°ìˆ , ê¸€ë¡œë²Œ ì„ í–‰ ì§€í‘œ ì¶”ê°€
2. **ë…ë¦½ì„± í™•ë³´**: ì§€ì—­ íŠ¹í™”, ê³„ì ˆì„±, ì™¸ìƒì¶©ê²©, êµ¬ì¡°ë³€í™”, ì¸êµ¬í•™ì  ìš”ì¸
3. **ë‹¤ì°¨ì›ì„±**: 5ê°œ ì˜ì—­ì˜ ì¢…í•©ì  ì§€í‘œ í†µí•©
4. **ì§€ì—­ë³„ ë§ì¶¤**: ë„ì‹œ/ë„ ì§€ì—­ë³„ ì°¨ë³„í™”ëœ ëª¨ë¸ë§

## ğŸ“‹ ê²°ë¡ 
í–¥ìƒëœ BDS ëª¨ë¸ì€ NAVISì˜ ì¥ì ì„ ìœ ì§€í•˜ë©´ì„œë„ ì„ í–‰ì„±ê³¼ ë…ë¦½ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
ì´ëŠ” NAVISë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ë”ìš± ê°•ë ¥í•œ ì§€ì—­ë°œì „ ì§€í‘œë¡œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""
    
    with open('enhanced_bds_model_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… ëª¨ë¸ ë³´ê³ ì„œ ì €ì¥: enhanced_bds_model_report.md")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„±ê¸° ===")
    
    # 1. NAVIS ë°ì´í„° ë¡œë“œ
    navis_df = load_navis_data()
    if navis_df is None:
        print("âŒ NAVIS ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # 2. ë‹¤ì°¨ì›ì  ì§€í‘œ ìƒì„±
    enhanced_df = create_multidimensional_indicators(navis_df)
    
    # 3. ì„ í–‰ ì§€í‘œ ìƒì„±
    leading_df = create_leading_indicators(enhanced_df)
    
    # 4. ë…ë¦½ì  ì§€í‘œ ìƒì„±
    independent_df = create_independent_indicators(enhanced_df)
    
    # 5. í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„±
    bds_df = create_enhanced_bds_model(enhanced_df, leading_df, independent_df)
    
    # 6. ëª¨ë¸ ê²€ì¦
    validation_results = validate_enhanced_model(bds_df)
    
    # 7. ëª¨ë¸ ì €ì¥
    save_enhanced_model(bds_df, validation_results)
    
    print(f"\nâœ… í–¥ìƒëœ BDS ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“Š ì£¼ìš” ì„±ê³¼:")
    print(f"  - ì„ í–‰ì„± ìš°ìœ„: {sum(1 for r in validation_results.values() if r['is_leading'])}ê°œ ì§€ì—­")
    print(f"  - ë…ë¦½ì„± ìš°ìœ„: {sum(1 for r in validation_results.values() if r['is_independent'])}ê°œ ì§€ì—­")
    print(f"  - í‰ê·  ë…ë¦½ì„±: {np.mean([r['independence_score'] for r in validation_results.values()]):.3f}")

if __name__ == "__main__":
    main()
